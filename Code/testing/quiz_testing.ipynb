{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfe015c-95c9-4a77-899b-63cae8af681d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai awswrangler --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325509dc-47ae-4bfd-8ca6-44b3c3ceffe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup of GPT-4 configurations for quizzing\n",
    "key_file = open('/home/ec2-user/SageMaker/open_key.txt')\n",
    "open_key = key_file.read()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42cd4a7e-8e65-44d8-8f6f-8150995bf7c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "athena = boto3.client(\"athena\")\n",
    "runtime = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf941f5-d472-468a-9920-1cf8204a1d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup of sqlcoder-7b configuration for quizzing\n",
    "sql_endpoint = \"https://yhkqe6os38yw017b.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "\n",
    "headers = {\n",
    "\t\"Authorization\": \"Bearer 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\",\n",
    "\t\"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21e4e5f9-d4e5-48e1-a5a6-497d59cd65da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup of llama2-13b-chat endpoint for quizzing\n",
    "llama_endpoint = \"interpreter-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da453e64-f58f-44c1-a26e-f01375619a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_ddl(table_name):\n",
    "    \"\"\" Get the DDL (table definition) of the Athena table to feed into the\n",
    "        Text-to-SQL prompt\n",
    "    \"\"\"\n",
    "    queryStart = athena.start_query_execution(\n",
    "        QueryString = \"SHOW CREATE TABLE {}\".format(table_name),\n",
    "        QueryExecutionContext = {\n",
    "            'Database': 'capstone_v3'\n",
    "        },\n",
    "        ResultConfiguration = { 'OutputLocation': 's3://aws-athena-query-results-820103179345-us-east-1/text2sql/'}\n",
    "    )\n",
    "    # Give enough time for the SQL query to execute\n",
    "    time.sleep(5)\n",
    "    queryExecution = athena.get_query_execution(QueryExecutionId=queryStart['QueryExecutionId'])\n",
    "    results = athena.get_query_results(QueryExecutionId=queryStart['QueryExecutionId'])\n",
    "        \n",
    "    ddl = \"\"\n",
    "    for i in range(len(results['ResultSet']['Rows'])):\n",
    "        ddl += results['ResultSet']['Rows'][i]['Data'][0]['VarCharValue']\n",
    "    ddl = ddl.split(')')[0]\n",
    "    \n",
    "    return ddl\n",
    "\n",
    "\n",
    "def ask_gpt(question):\n",
    "    \"\"\" Ask GPT-4 a question\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Given the following SQL tables, your job is to write queries given a user's request. Only return SQL queries- no extra text \\n {} {};\".format(get_ddl('predictions'), get_ddl('telemetry_extended_v3'))\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "        )\n",
    "\n",
    "    output_query = response.choices[0].message.content\n",
    "    gpt_text2sql_time = time.time() - start\n",
    "    print(\"gpt time: \", str(gpt_text2sql_time))\n",
    "    \n",
    "    print(output_query)\n",
    "    \n",
    "    context = \"Here is the context: We are looking at industrial factory machine data. Speed differences of 232 and over are worse as you get higher. You will be provided a string representation of a dataframe with SQL query results. Your job is to summarize thes results and give recommendations for how to address these issues. Here is the corresponding SQL query: \" + output_query\n",
    "\n",
    "    athena_result = \"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    try:\n",
    "        df = wr.athena.read_sql_query(\n",
    "            sql=output_query,\n",
    "            database='capstone_v3',\n",
    "            ctas_approach=True)\n",
    "        athena_result = str(df.head(15))\n",
    "    except:\n",
    "        athena_result = \"The query outputted by sqlcoder could not be processed by Athena!\"\n",
    "    \n",
    "    athena_time = time.time() - start\n",
    "    print(\"athena_time: \", str(athena_time))\n",
    "    \n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": context\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Evaluate the following output: {}. If the query was successful, interpret the dataframe. If the query failed, communicate that to the user:\".format(athena_result)\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0)\n",
    "    interpretation_time = time.time() - start\n",
    "    print(\"interpretation_time: \", str(interpretation_time))\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(sql_endpoint, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "def ask_open_source(question):\n",
    "    \n",
    "    prompt = \"\"\"### Task\n",
    "    Generate a SQL query to answer the following question:\n",
    "    `{question}`\n",
    "\n",
    "    ### Database Schema\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "    `{pred_ddl}`;\n",
    "\n",
    "    `{telemetry_ddl}`;\n",
    "\n",
    "    -- the prediction table's columns each represent the predictions of a vehicle's risk scores\n",
    "    -- the telemetry table contains a timeseries of machines along with metrics collected for each record\n",
    "    ;\n",
    "\n",
    "    ### SQL\n",
    "    Given the database schema, here is the SQL query that answers `{question}`:\n",
    "    ```sql\n",
    "    \"\"\".format(question=question, pred_ddl=get_ddl('predictions'), telemetry_ddl=get_ddl('telemetry_extended_v3'))\n",
    "    \n",
    "    output = query({\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {'max_new_tokens': 500, \"top_p\": 0.1, \"temperature\": 0.2}\n",
    "    })\n",
    "    \n",
    "    output_query = output[0]['generated_text']\n",
    "    output_query = output_query.replace('\\n','')\n",
    "    output_query = output_query.replace('```','')\n",
    "    \n",
    "    print(output_query)\n",
    "    \n",
    "    try:\n",
    "        df = wr.athena.read_sql_query(\n",
    "            sql=question1_open,\n",
    "            database='capstone_v3',\n",
    "            ctas_approach=True)\n",
    "        athena_result = str(df)\n",
    "    except:\n",
    "        athena_result = \"The query outputted by sqlcoder could not be processed by Athena!\"\n",
    "    \n",
    "    input_prompt = f\"\"\"[INST] <<SYS>>\n",
    "    Your job is to interpret the results from the following query results: {athena_result}. If the query failed, just say that and nothing else. If the query didn't fail, provide recommendations on how to fix these issues.\n",
    "    <</SYS>>{question} [/INST]\"\"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"inputs\": input_prompt,\n",
    "        \"parameters\": {\"max_new_tokens\": 500, \"top_p\": 0.1, \"temperature\": 0.5}\n",
    "    }\n",
    "    \n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=llama_endpoint,\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType='application/json')\n",
    "    \n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    \n",
    "    return result[0]['generated_text'].split('[/INST]')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582e5a2-0aad-416e-a86e-15d092bcd027",
   "metadata": {},
   "source": [
    "### Question 1: Give me the machines that had the highest pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1944ba7-d59e-4f48-be80-c9557a86524f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question1 = \"Give me the machines that had the highest pressure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3199db56-a1e4-4fb4-ab92-64b852e4097e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt time:  11.452497243881226\n",
      "SELECT machineid, MAX(pressure) as max_pressure\n",
      "FROM telemetry_extended_v3\n",
      "GROUP BY machineid\n",
      "ORDER BY max_pressure DESC;\n",
      "athena_time:  4.024524688720703\n",
      "interpretation_time:  7.920696258544922\n",
      "The SQL query was successful and it returned a dataframe with two columns: 'machineid' and 'max_pressure'. The dataframe lists the maximum pressure recorded by each machine in descending order. \n",
      "\n",
      "The machine with the highest recorded pressure is M_0017 with a pressure of 2694.20. The machine with the lowest maximum pressure in this list is M_0008 with a pressure of 2591.06. \n",
      "\n",
      "If high pressure is a concern for the operation of these machines, it would be recommended to investigate the machines with the highest pressures, starting with M_0017. It would be beneficial to understand why these machines are experiencing such high pressures and if there are any common factors among them. \n",
      "\n",
      "If the speed differences of 232 and over are worse as you get higher, it would be important to check if these pressure levels are causing such speed differences. If so, measures should be taken to reduce the pressure levels in these machines to improve their performance and longevity.\n"
     ]
    }
   ],
   "source": [
    "question1_gpt = ask_gpt(question1)\n",
    "print(question1_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8337b4e2-80e6-430f-b688-d93828b63645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SELECT machineid, MAX(pressure) AS max_pressure FROM telemetry_extended_v3 WHERE timestamp BETWEEN '2020-01-01' AND '2020-12-31' GROUP BY machineid ORDER BY max_pressure DESC NULLS LAST;    \n",
      "  The query outputted by sqlcoder could not be processed by Athena!\n",
      "\n",
      "The error message from Athena was:\n",
      "\n",
      "\"Invalid SQL: Unknown column 'pressure' in 'where clause'\"\n",
      "\n",
      "This error message indicates that the column 'pressure' does not exist in the table or view being queried.\n",
      "\n",
      "To fix this issue, you can try the following:\n",
      "\n",
      "1. Check the table or view definition to ensure that the column 'pressure' exists and is of the correct data type.\n",
      "2. Verify that the column name is spelled correctly and is not case-sensitive.\n",
      "3. If the column does not exist, you may need to add it to the table or view definition.\n",
      "\n",
      "Once you have resolved the issue, you can try running the query again to retrieve the machines with the highest pressure.\n"
     ]
    }
   ],
   "source": [
    "question1_open = ask_open_source(question1)\n",
    "print(question1_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead780f7-6a32-44ba-8a76-361ab8da52c1",
   "metadata": {},
   "source": [
    "### Question 2: Which machines had the highest temperature and when?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "135b6493-3eb6-45a3-a5ca-e96eb3eae9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question2 = \"Which machines had the highest temperature?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82963be6-82c0-4023-ab3d-cb6a626c1c56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT machineid, MAX(temperature) as max_temperature\n",
      "FROM telemetry_extended_v3\n",
      "GROUP BY machineid\n",
      "ORDER BY max_temperature DESC;\n",
      "The query was successful. The dataframe shows the maximum temperature recorded for each machine in the factory. The machines are ordered by their maximum temperature in descending order. \n",
      "\n",
      "The machine with the highest recorded temperature is M_0002 and M_0005, both reaching a maximum temperature of 215.00. The machine with the lowest maximum temperature is M_0018 with a temperature of 214.91.\n",
      "\n",
      "Since the speed differences of 232 and over are worse as you get higher, none of the machines have reached this critical level yet. However, it's important to monitor the machines, especially M_0002 and M_0005, as they have the highest recorded temperatures. \n",
      "\n",
      "Recommendations:\n",
      "1. Regularly monitor the temperature of all machines, especially those with higher maximum temperatures.\n",
      "2. Implement a warning system to alert when a machine's temperature is nearing the critical level of 232.\n",
      "3. Regular maintenance and checks should be performed to ensure machines are working efficiently and not overheating.\n",
      "4. If a machine consistently records high temperatures, it may be worth investigating if there is a fault with the machine or if it's being overworked.\n"
     ]
    }
   ],
   "source": [
    "print(ask_gpt(question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e34de446-af62-435c-a332-37b26ba5778c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SELECT machineid, MAX(temperature) AS max_temperature FROM telemetry_extended_v3 WHERE timestamp >= CURRENT_DATE - interval '7 days' GROUP BY machineid ORDER BY max_temperature DESC NULLS LAST;    \n",
      "  The query outputted by sqlcoder could not be processed by Athena!\n",
      "\n",
      "The error message suggests that there was a problem with the query itself, rather than an issue with the data or the machine. Without more information, it's difficult to provide specific recommendations on how to fix the issue. However, here are a few general tips that may help:\n",
      "\n",
      "1. Check the syntax of the query: Make sure that the query is written correctly and that all of the necessary syntax is included.\n",
      "2. Check the data types of the columns: Ensure that the data types of the columns in the query match the data types of the columns in the table.\n",
      "3. Check for missing or invalid data: Make sure that all of the required data is present and that it is in the correct format.\n",
      "4. Check for duplicate or redundant data: Remove any duplicate or redundant data that may be causing the query to fail.\n",
      "5. Check the machine learning settings: If the query is using machine learning, check the settings to ensure that they are correct and that the model is properly trained.\n",
      "\n",
      "Without more information, it is difficult to provide specific recommendations on how to fix the issue. If you have any additional information or context, please provide it and I will do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "print(ask_open_source(question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17ccf3f0-2212-4f7f-8d6f-c1b7c92356a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_7b(llama_endpoint, athena_client, sagemaker_client, question):\n",
    "    \n",
    "    prompt = \"\"\"### Task\n",
    "    Generate a SQL query to answer the following question:\n",
    "    `{question}`\n",
    "\n",
    "    ### Database Schema\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "    `{pred_ddl}`;\n",
    "\n",
    "    `{telemetry_ddl}`;\n",
    "\n",
    "    -- the prediction table's columns each represent the predictions of a vehicle's risk scores\n",
    "    -- the telemetry table contains a timeseries of machines along with metrics collected for each record\n",
    "    ;\n",
    "\n",
    "    ### SQL\n",
    "    Given the database schema, here is the SQL query that answers `{question}`:\n",
    "    ```sql\n",
    "    \"\"\".format(question=question, pred_ddl=get_ddl('predictions'), telemetry_ddl=get_ddl('telemetry_extended_v3'))\n",
    "    \n",
    "    start = time.time()\n",
    "    output = query({\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {'max_new_tokens': 500, \"top_p\": 0.1, \"temperature\": 0.2}\n",
    "    })\n",
    "    \n",
    "    output_query = output[0]['generated_text']\n",
    "    output_query = output_query.replace('\\n','')\n",
    "    output_query = output_query.replace('```','')\n",
    "    output_query = output_query.replace(\"' '\",\"\")\n",
    "    \n",
    "    text2sql_time = time.time() - start\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    query_success = 0\n",
    "    \n",
    "    try:\n",
    "        df = wr.athena.read_sql_query(\n",
    "            sql=output_query,\n",
    "            database='capstone_v3',\n",
    "            ctas_approach=True)\n",
    "        athena_result = str(df.head(15))\n",
    "        query_success = 1\n",
    "    except:\n",
    "        athena_result = \"The query could not be processed by Athena!\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    query_time = time.time() - start\n",
    "    \n",
    "\n",
    "    \n",
    "    input_prompt = f\"\"\"[INST] <<SYS>>\n",
    "    Your job is to interpret the results from the following query results: {athena_result}. If the query failed, just say that and nothing else. If the query didn't fail, provide recommendations on how to fix these issues.\n",
    "    <</SYS>>{question} [/INST]\"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    payload = {\n",
    "        \"inputs\": input_prompt,\n",
    "        \"parameters\": {\"max_new_tokens\": 500, \"top_p\": 0.1, \"temperature\": 0.5}\n",
    "    }\n",
    "    inter_time = time.time() - start\n",
    "    \n",
    "    response = sagemaker_client.invoke_endpoint(\n",
    "        EndpointName=llama_endpoint,\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType='application/json')\n",
    "    \n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    result = result[0]['generated_text'].split('[/INST]')[1]\n",
    "    \n",
    "    return {\n",
    "        \"LLM\": \"sqlcoder-7b\",\n",
    "        \"question\": question,\n",
    "        \"query\": output_query,\n",
    "        \"interpretation\": result,\n",
    "        \"text2sql_time\": np.round(text2sql_time,2),\n",
    "        \"query_time\": np.round(query_time,2),\n",
    "        \"query_success\": query_success,\n",
    "        \"interpretation_time\": np.round(inter_time,2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7682a00e-e508-4275-9b79-70b166b99dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question1 = \"what devices have the highest temperatures?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67b6f3f5-cfc3-45c3-8b36-a173a93a00c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LLM': 'sqlcoder-7b', 'question': 'what devices have the highest temperatures?', 'query': ' SELECT machineid, MAX(temperature) AS max_temperature FROM telemetry_extended_v3 GROUP BY machineid ORDER BY max_temperature DESC NULLS LAST;    ', 'interpretation': \"  Based on the query results you provided, the devices with the highest temperatures are:\\n\\n1. M_0005 with a maximum temperature of 215.00\\n2. M_0024 with a maximum temperature of 214.99\\n3. M_0012 with a maximum temperature of 214.99\\n4. M_0015 with a maximum temperature of 214.99\\n5. M_0000 with a maximum temperature of 214.99\\n\\nAll of these devices have a maximum temperature of 214.99 or higher, indicating that they are operating at high temperatures.\\n\\nTo fix these issues, you may want to consider the following recommendations:\\n\\n1. Check the cooling system of these devices to ensure that it is functioning properly and that there are no blockages or malfunctions that could be causing the high temperatures.\\n2. Consider upgrading the cooling system or adding additional cooling components to these devices to help reduce the temperature.\\n3. Check for any software or firmware updates that may help address the issue.\\n4. If the high temperatures are caused by a hardware failure, consider replacing the affected components.\\n\\nIt's important to note that if the query failed, it may be due to a lack of data or a problem with the query itself. In this case, you may need to troubleshoot the issue and try again with a different query or more data.\", 'text2sql_time': 1.88, 'query_time': 4.06, 'query_success': 1, 'interpretation_time': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(ask_7b(llama_endpoint, athena, runtime, question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b23ca14f-676e-4d81-8499-1809fb6d5376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_34b(llama_endpoint, athena_client, sagemaker_client, question):\n",
    "    \n",
    "    prompt = \"\"\"### Task\n",
    "    Generate a SQL query to answer the following question:\n",
    "    `{question}`\n",
    "\n",
    "    ### Database Schema\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "    `{pred_ddl}`;\n",
    "\n",
    "    `{telemetry_ddl}`;\n",
    "\n",
    "    -- the prediction table's columns each represent the predictions of a vehicle's risk scores\n",
    "    -- the telemetry table contains a timeseries of machines along with metrics collected for each record\n",
    "    ;\n",
    "\n",
    "    ### SQL\n",
    "    Given the database schema, here is the SQL query that answers `{question}`:\n",
    "    ```sql\n",
    "    \"\"\".format(question=question, pred_ddl=get_ddl('predictions'), telemetry_ddl=get_ddl('telemetry_extended_v3'))\n",
    "    \n",
    "    start = time.time()\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\"max_new_tokens\": 500, \"top_p\": 0.1, \"temperature\": 0.5}\n",
    "    }\n",
    "    \n",
    "    response = sagemaker_client.invoke_endpoint(\n",
    "        EndpointName=\"text2sql-34b\",\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType='application/json')\n",
    "    \n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    output_query = result[0]['generated_text'].split('```sql')[1].split('```')[0]\n",
    "    \n",
    "    text2sql_time = time.time() - start\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    query_success = 0\n",
    "    \n",
    "    try:\n",
    "        df = wr.athena.read_sql_query(\n",
    "            sql=output_query,\n",
    "            database='capstone_v3',\n",
    "            ctas_approach=True)\n",
    "        athena_result = str(df.head(15))\n",
    "        query_success = 1\n",
    "    except:\n",
    "        athena_result = \"The query could not be processed by Athena!\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    query_time = time.time() - start\n",
    "    \n",
    "\n",
    "    \n",
    "    input_prompt = f\"\"\"[INST] <<SYS>>\n",
    "    Your job is to interpret the results from the following query results: {athena_result}. If the query failed, just say that and nothing else. If the query didn't fail, provide recommendations on how to fix these issues.\n",
    "    <</SYS>>{question} [/INST]\"\"\"\n",
    "    \n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": input_prompt,\n",
    "        \"parameters\": {\"max_new_tokens\": 500, \"top_p\": 0.1, \"temperature\": 0.5}\n",
    "    }\n",
    "    \n",
    "    start = time.time()\n",
    "    response = sagemaker_client.invoke_endpoint(\n",
    "        EndpointName=llama_endpoint,\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType='application/json')\n",
    "    inter_time = time.time() - start\n",
    "    \n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    result = result[0]['generated_text'].split('[/INST]')[1]\n",
    "    \n",
    "    return {\n",
    "        \"LLM\": \"sqlcoder-34b\",\n",
    "        \"question\": question,\n",
    "        \"query\": output_query,\n",
    "        \"interpretation\": result,\n",
    "        \"text2sql_time\": np.round(text2sql_time,2),\n",
    "        \"query_time\": np.round(query_time,2),\n",
    "        \"query_success\": query_success,\n",
    "        \"interpretation_time\": np.round(inter_time,2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c08c6b50-3bc0-407f-a248-720a801603fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LLM': 'sqlcoder-34b', 'question': 'what devices have the highest temperatures?', 'query': '\\n     SELECT machineid, MAX(temperature) AS max_temperature FROM telemetry_extended_v3 GROUP BY machineid ORDER BY max_temperature DESC;\\n    ', 'interpretation': \"  Based on the query results you provided, the devices with the highest temperatures are:\\n\\n1. M_0005 with a maximum temperature of 215.00\\n2. M_0002 with a maximum temperature of 215.00\\n3. M_0024 with a maximum temperature of 214.99\\n\\nAll of these devices have a maximum temperature of 215.00, which is the highest temperature recorded in the query results.\\n\\nThere are no obvious issues with the query results, but it's worth noting that the temperatures are all very close to each other, which may indicate that the temperature readings are not very precise. Additionally, there are several devices with maximum temperatures of 214.99, which is just below the highest temperature recorded. This may indicate that there is some variability in the temperature readings or that the devices are not being accurately calibrated.\\n\\nTo fix these issues, you may want to consider the following recommendations:\\n\\n1. Check the calibration of the temperature sensors to ensure that they are accurately measuring temperature.\\n2. Consider using a more precise temperature measurement tool, such as a thermometer with a higher resolution, to record temperature readings.\\n3. Implement quality control measures to ensure that temperature readings are consistent and accurate. This may include regularly calibrating temperature sensors and checking for any anomalies in the temperature readings.\\n4. Consider using a different query or analysis method to identify devices with high temperatures, such as calculating the average temperature or using a statistical analysis tool to identify outliers.\", 'text2sql_time': 2.24, 'query_time': 5.06, 'query_success': 1, 'interpretation_time': 7.95}\n"
     ]
    }
   ],
   "source": [
    "question1 = \"what devices have the highest temperatures?\"\n",
    "print(ask_34b(llama_endpoint, athena, runtime, question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5536b-ea78-4120-a8f8-3e2238e0e4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6125a5-bece-42ae-84ca-c827e74f97f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32bd9ac-f328-4e79-afd2-9bad82ebf3a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (3.4.2)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from awswrangler) (1.28.80)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from awswrangler) (1.31.80)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from awswrangler) (1.26.2)\n",
      "Requirement already satisfied: packaging<24.0,>=21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from awswrangler) (21.3)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from awswrangler) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=7.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from awswrangler) (13.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from awswrangler) (4.5.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (1.26.18)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from packaging<24.0,>=21.1->awswrangler) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install awswrangler\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install -U numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2a1e3-6f04-4d56-8eb9-f4a550f340c8",
   "metadata": {},
   "source": [
    "In this notebook, I use the criteria I defined during data exploration to assign risk scores to each record and eventually train a DeepAR Forecasting model on that data. First, I'll start with assining the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3eb29d-c289-43b2-aaf2-23261a5e3f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = wr.athena.read_sql_query(\n",
    "    sql=\"SELECT DISTINCT timestamp, machineid, speed_difference, speed, temperature, pressure FROM telemetry_extended_v3 WHERE rand() <= 0.1 ORDER BY timestamp\",\n",
    "    database='capstone_v3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b13189b-b481-40a9-97c6-0b42191accc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91455315-3829-4efa-83c6-6328081eb249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>machineid</th>\n",
       "      <th>speed_difference</th>\n",
       "      <th>speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524300</th>\n",
       "      <td>2021-11-01 00:05:32</td>\n",
       "      <td>M_0012</td>\n",
       "      <td>138.00</td>\n",
       "      <td>1138.00</td>\n",
       "      <td>136.91</td>\n",
       "      <td>1530.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524301</th>\n",
       "      <td>2021-11-01 00:05:55</td>\n",
       "      <td>M_0012</td>\n",
       "      <td>136.09</td>\n",
       "      <td>1136.09</td>\n",
       "      <td>136.94</td>\n",
       "      <td>1539.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524302</th>\n",
       "      <td>2021-11-01 00:06:44</td>\n",
       "      <td>M_0005</td>\n",
       "      <td>101.97</td>\n",
       "      <td>1101.97</td>\n",
       "      <td>143.58</td>\n",
       "      <td>1267.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524303</th>\n",
       "      <td>2021-11-01 00:07:03</td>\n",
       "      <td>M_0005</td>\n",
       "      <td>101.85</td>\n",
       "      <td>1101.85</td>\n",
       "      <td>143.57</td>\n",
       "      <td>1273.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524304</th>\n",
       "      <td>2021-11-01 00:07:17</td>\n",
       "      <td>M_0005</td>\n",
       "      <td>105.41</td>\n",
       "      <td>1105.41</td>\n",
       "      <td>143.70</td>\n",
       "      <td>1285.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610426</th>\n",
       "      <td>2023-10-31 18:56:30</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>131.31</td>\n",
       "      <td>1131.31</td>\n",
       "      <td>141.52</td>\n",
       "      <td>1379.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610427</th>\n",
       "      <td>2023-10-31 18:57:11</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>134.92</td>\n",
       "      <td>1134.92</td>\n",
       "      <td>141.54</td>\n",
       "      <td>1376.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610428</th>\n",
       "      <td>2023-10-31 18:57:12</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>131.48</td>\n",
       "      <td>1131.48</td>\n",
       "      <td>141.48</td>\n",
       "      <td>1371.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610429</th>\n",
       "      <td>2023-10-31 18:58:14</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>135.77</td>\n",
       "      <td>1135.77</td>\n",
       "      <td>141.53</td>\n",
       "      <td>1395.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610430</th>\n",
       "      <td>2023-10-31 18:58:23</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>129.47</td>\n",
       "      <td>1129.47</td>\n",
       "      <td>141.64</td>\n",
       "      <td>1394.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647881 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp machineid  speed_difference    speed  temperature  \\\n",
       "524300 2021-11-01 00:05:32    M_0012            138.00  1138.00       136.91   \n",
       "524301 2021-11-01 00:05:55    M_0012            136.09  1136.09       136.94   \n",
       "524302 2021-11-01 00:06:44    M_0005            101.97  1101.97       143.58   \n",
       "524303 2021-11-01 00:07:03    M_0005            101.85  1101.85       143.57   \n",
       "524304 2021-11-01 00:07:17    M_0005            105.41  1105.41       143.70   \n",
       "...                    ...       ...               ...      ...          ...   \n",
       "610426 2023-10-31 18:56:30    M_0023            131.31  1131.31       141.52   \n",
       "610427 2023-10-31 18:57:11    M_0023            134.92  1134.92       141.54   \n",
       "610428 2023-10-31 18:57:12    M_0023            131.48  1131.48       141.48   \n",
       "610429 2023-10-31 18:58:14    M_0023            135.77  1135.77       141.53   \n",
       "610430 2023-10-31 18:58:23    M_0023            129.47  1129.47       141.64   \n",
       "\n",
       "        pressure  \n",
       "524300   1530.45  \n",
       "524301   1539.29  \n",
       "524302   1267.20  \n",
       "524303   1273.77  \n",
       "524304   1285.64  \n",
       "...          ...  \n",
       "610426   1379.57  \n",
       "610427   1376.95  \n",
       "610428   1371.51  \n",
       "610429   1395.87  \n",
       "610430   1394.75  \n",
       "\n",
       "[647881 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='timestamp', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c068c67-8429-40f2-8730-0e4402bf9087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_score(row):\n",
    "    risk_score = 0\n",
    "    \n",
    "    # Check Temperature\n",
    "    if row['temperature'] > 200:\n",
    "        risk_score += 3\n",
    "    elif 175 < row['temperature'] < 200:\n",
    "        risk_score += 2\n",
    "    elif 150 < row['temperature'] < 175:\n",
    "        risk_score += 1\n",
    "    \n",
    "    # Check Pressure\n",
    "    if row['pressure'] < 482:\n",
    "        risk_score += 1\n",
    "    elif row['pressure'] > 2114:\n",
    "        risk_score += 2\n",
    "    \n",
    "    # Check Speed Difference\n",
    "    if row['speed_difference'] > 600:\n",
    "        risk_score += 4\n",
    "    elif 500 < row['speed_difference'] < 600:\n",
    "        risk_score += 3\n",
    "    elif 400 < row['speed_difference'] < 500:\n",
    "        risk_score += 2\n",
    "    elif 200 < row['speed_difference'] < 400:\n",
    "        risk_score += 1\n",
    "        \n",
    "    return risk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68fa2c35-cb1b-4a26-904d-fce8dd5708bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['risk_score'] = df.apply(assign_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466c475c-a23a-4901-ab9c-df19a30b9766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>machineid</th>\n",
       "      <th>speed_difference</th>\n",
       "      <th>speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524300</th>\n",
       "      <td>2021-11-01 00:05:32</td>\n",
       "      <td>M_0012</td>\n",
       "      <td>138.00</td>\n",
       "      <td>1138.00</td>\n",
       "      <td>136.91</td>\n",
       "      <td>1530.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524301</th>\n",
       "      <td>2021-11-01 00:05:55</td>\n",
       "      <td>M_0012</td>\n",
       "      <td>136.09</td>\n",
       "      <td>1136.09</td>\n",
       "      <td>136.94</td>\n",
       "      <td>1539.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524302</th>\n",
       "      <td>2021-11-01 00:06:44</td>\n",
       "      <td>M_0005</td>\n",
       "      <td>101.97</td>\n",
       "      <td>1101.97</td>\n",
       "      <td>143.58</td>\n",
       "      <td>1267.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524303</th>\n",
       "      <td>2021-11-01 00:07:03</td>\n",
       "      <td>M_0005</td>\n",
       "      <td>101.85</td>\n",
       "      <td>1101.85</td>\n",
       "      <td>143.57</td>\n",
       "      <td>1273.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524304</th>\n",
       "      <td>2021-11-01 00:07:17</td>\n",
       "      <td>M_0005</td>\n",
       "      <td>105.41</td>\n",
       "      <td>1105.41</td>\n",
       "      <td>143.70</td>\n",
       "      <td>1285.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610426</th>\n",
       "      <td>2023-10-31 18:56:30</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>131.31</td>\n",
       "      <td>1131.31</td>\n",
       "      <td>141.52</td>\n",
       "      <td>1379.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610427</th>\n",
       "      <td>2023-10-31 18:57:11</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>134.92</td>\n",
       "      <td>1134.92</td>\n",
       "      <td>141.54</td>\n",
       "      <td>1376.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610428</th>\n",
       "      <td>2023-10-31 18:57:12</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>131.48</td>\n",
       "      <td>1131.48</td>\n",
       "      <td>141.48</td>\n",
       "      <td>1371.51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610429</th>\n",
       "      <td>2023-10-31 18:58:14</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>135.77</td>\n",
       "      <td>1135.77</td>\n",
       "      <td>141.53</td>\n",
       "      <td>1395.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610430</th>\n",
       "      <td>2023-10-31 18:58:23</td>\n",
       "      <td>M_0023</td>\n",
       "      <td>129.47</td>\n",
       "      <td>1129.47</td>\n",
       "      <td>141.64</td>\n",
       "      <td>1394.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647881 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp machineid  speed_difference    speed  temperature  \\\n",
       "524300 2021-11-01 00:05:32    M_0012            138.00  1138.00       136.91   \n",
       "524301 2021-11-01 00:05:55    M_0012            136.09  1136.09       136.94   \n",
       "524302 2021-11-01 00:06:44    M_0005            101.97  1101.97       143.58   \n",
       "524303 2021-11-01 00:07:03    M_0005            101.85  1101.85       143.57   \n",
       "524304 2021-11-01 00:07:17    M_0005            105.41  1105.41       143.70   \n",
       "...                    ...       ...               ...      ...          ...   \n",
       "610426 2023-10-31 18:56:30    M_0023            131.31  1131.31       141.52   \n",
       "610427 2023-10-31 18:57:11    M_0023            134.92  1134.92       141.54   \n",
       "610428 2023-10-31 18:57:12    M_0023            131.48  1131.48       141.48   \n",
       "610429 2023-10-31 18:58:14    M_0023            135.77  1135.77       141.53   \n",
       "610430 2023-10-31 18:58:23    M_0023            129.47  1129.47       141.64   \n",
       "\n",
       "        pressure  risk_score  \n",
       "524300   1530.45           0  \n",
       "524301   1539.29           0  \n",
       "524302   1267.20           0  \n",
       "524303   1273.77           0  \n",
       "524304   1285.64           0  \n",
       "...          ...         ...  \n",
       "610426   1379.57           0  \n",
       "610427   1376.95           0  \n",
       "610428   1371.51           0  \n",
       "610429   1395.87           0  \n",
       "610430   1394.75           0  \n",
       "\n",
       "[647881 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2494740b-b3d8-4e7e-a0a8-7478fd01c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['risk_score'].hist()\n",
    "plt.title(\"Risk Score Distribution\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff87d8-dbd0-416c-a0ea-0f14cab295ad",
   "metadata": {},
   "source": [
    "For historic data, I'll look at vehicles that have a risk score of over 5 because that means that there are at least 2 issues with the machine, based on the scoring criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b424875-b47e-4eac-9c23-1009bc65005b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>machineid</th>\n",
       "      <th>speed_difference</th>\n",
       "      <th>speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527836</th>\n",
       "      <td>2021-11-04 21:35:23</td>\n",
       "      <td>M_0014</td>\n",
       "      <td>541.62</td>\n",
       "      <td>1541.62</td>\n",
       "      <td>140.50</td>\n",
       "      <td>2132.93</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530710</th>\n",
       "      <td>2021-11-08 03:23:21</td>\n",
       "      <td>M_0022</td>\n",
       "      <td>686.08</td>\n",
       "      <td>1686.08</td>\n",
       "      <td>143.08</td>\n",
       "      <td>2282.08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530760</th>\n",
       "      <td>2021-11-08 03:52:20</td>\n",
       "      <td>M_0006</td>\n",
       "      <td>609.75</td>\n",
       "      <td>1609.75</td>\n",
       "      <td>138.74</td>\n",
       "      <td>2333.21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530762</th>\n",
       "      <td>2021-11-08 03:52:37</td>\n",
       "      <td>M_0006</td>\n",
       "      <td>679.08</td>\n",
       "      <td>1679.08</td>\n",
       "      <td>138.70</td>\n",
       "      <td>2440.89</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531199</th>\n",
       "      <td>2021-11-08 15:52:40</td>\n",
       "      <td>M_0003</td>\n",
       "      <td>610.86</td>\n",
       "      <td>610.86</td>\n",
       "      <td>152.81</td>\n",
       "      <td>881.41</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607791</th>\n",
       "      <td>2023-10-28 18:15:53</td>\n",
       "      <td>M_0015</td>\n",
       "      <td>548.81</td>\n",
       "      <td>1548.81</td>\n",
       "      <td>139.51</td>\n",
       "      <td>2155.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607792</th>\n",
       "      <td>2023-10-28 18:16:09</td>\n",
       "      <td>M_0015</td>\n",
       "      <td>568.50</td>\n",
       "      <td>1568.50</td>\n",
       "      <td>139.55</td>\n",
       "      <td>2196.18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607880</th>\n",
       "      <td>2023-10-28 21:07:00</td>\n",
       "      <td>M_0020</td>\n",
       "      <td>437.22</td>\n",
       "      <td>562.78</td>\n",
       "      <td>181.05</td>\n",
       "      <td>124.97</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607950</th>\n",
       "      <td>2023-10-28 21:55:16</td>\n",
       "      <td>M_0011</td>\n",
       "      <td>568.54</td>\n",
       "      <td>1568.54</td>\n",
       "      <td>142.45</td>\n",
       "      <td>2117.26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607951</th>\n",
       "      <td>2023-10-28 21:55:35</td>\n",
       "      <td>M_0011</td>\n",
       "      <td>600.65</td>\n",
       "      <td>1600.65</td>\n",
       "      <td>142.59</td>\n",
       "      <td>2169.14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp machineid  speed_difference    speed  temperature  \\\n",
       "527836 2021-11-04 21:35:23    M_0014            541.62  1541.62       140.50   \n",
       "530710 2021-11-08 03:23:21    M_0022            686.08  1686.08       143.08   \n",
       "530760 2021-11-08 03:52:20    M_0006            609.75  1609.75       138.74   \n",
       "530762 2021-11-08 03:52:37    M_0006            679.08  1679.08       138.70   \n",
       "531199 2021-11-08 15:52:40    M_0003            610.86   610.86       152.81   \n",
       "...                    ...       ...               ...      ...          ...   \n",
       "607791 2023-10-28 18:15:53    M_0015            548.81  1548.81       139.51   \n",
       "607792 2023-10-28 18:16:09    M_0015            568.50  1568.50       139.55   \n",
       "607880 2023-10-28 21:07:00    M_0020            437.22   562.78       181.05   \n",
       "607950 2023-10-28 21:55:16    M_0011            568.54  1568.54       142.45   \n",
       "607951 2023-10-28 21:55:35    M_0011            600.65  1600.65       142.59   \n",
       "\n",
       "        pressure  risk_score  \n",
       "527836   2132.93           5  \n",
       "530710   2282.08           6  \n",
       "530760   2333.21           6  \n",
       "530762   2440.89           6  \n",
       "531199    881.41           5  \n",
       "...          ...         ...  \n",
       "607791   2155.25           5  \n",
       "607792   2196.18           5  \n",
       "607880    124.97           5  \n",
       "607950   2117.26           5  \n",
       "607951   2169.14           6  \n",
       "\n",
       "[651 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['risk_score'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4c7774-740f-4d39-8eb7-2ae46f82484c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "['M_0014', 'M_0022', 'M_0006', 'M_0003', 'M_0007', 'M_0024', 'M_0000',\n",
       " 'M_0001', 'M_0012', 'M_0011', 'M_0015', 'M_0002', 'M_0020', 'M_0019',\n",
       " 'M_0008', 'M_0017', 'M_0021', 'M_0004', 'M_0010', 'M_0013', 'M_0018',\n",
       " 'M_0023', 'M_0016', 'M_0009', 'M_0005']\n",
       "Length: 25, dtype: string"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_risk = df[df['risk_score'] >= 5]\n",
    "high_risk['machineid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "333175c4-40e2-4ac5-aac5-cf8a99a0ab9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wr.s3.to_parquet(\n",
    "#     dataset=True,\n",
    "#     df=high_risk,\n",
    "#     database='capstone_v3',\n",
    "#     path=\"s3://predictive-maintenance-capstone-sn/data/high_risk_v3/\",\n",
    "#     table='high_risk_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790644f4-4646-47af-916d-99b3625b6e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9237a69-19ef-4cae-88e5-382613b24454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>machineid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>M_0000</th>\n",
       "      <th>M_0001</th>\n",
       "      <th>M_0002</th>\n",
       "      <th>M_0003</th>\n",
       "      <th>M_0004</th>\n",
       "      <th>M_0005</th>\n",
       "      <th>M_0006</th>\n",
       "      <th>M_0007</th>\n",
       "      <th>M_0008</th>\n",
       "      <th>...</th>\n",
       "      <th>M_0015</th>\n",
       "      <th>M_0016</th>\n",
       "      <th>M_0017</th>\n",
       "      <th>M_0018</th>\n",
       "      <th>M_0019</th>\n",
       "      <th>M_0020</th>\n",
       "      <th>M_0021</th>\n",
       "      <th>M_0022</th>\n",
       "      <th>M_0023</th>\n",
       "      <th>M_0024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-01 00:05:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-01 00:05:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-01 00:06:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-01 00:07:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-01 00:07:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638213</th>\n",
       "      <td>2023-10-31 18:56:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638214</th>\n",
       "      <td>2023-10-31 18:57:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638215</th>\n",
       "      <td>2023-10-31 18:57:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638216</th>\n",
       "      <td>2023-10-31 18:58:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638217</th>\n",
       "      <td>2023-10-31 18:58:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638218 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "machineid           timestamp  M_0000     M_0001     M_0002     M_0003     \\\n",
       "0         2021-11-01 00:05:32        NaN        NaN        NaN        NaN   \n",
       "1         2021-11-01 00:05:55        NaN        NaN        NaN        NaN   \n",
       "2         2021-11-01 00:06:44        NaN        NaN        NaN        NaN   \n",
       "3         2021-11-01 00:07:03        NaN        NaN        NaN        NaN   \n",
       "4         2021-11-01 00:07:17        NaN        NaN        NaN        NaN   \n",
       "...                       ...        ...        ...        ...        ...   \n",
       "638213    2023-10-31 18:56:30        NaN        NaN        NaN        NaN   \n",
       "638214    2023-10-31 18:57:11        NaN        NaN        NaN        NaN   \n",
       "638215    2023-10-31 18:57:12        NaN        NaN        NaN        NaN   \n",
       "638216    2023-10-31 18:58:14        NaN        NaN        NaN        NaN   \n",
       "638217    2023-10-31 18:58:23        NaN        NaN        NaN        NaN   \n",
       "\n",
       "machineid  M_0004     M_0005     M_0006     M_0007     M_0008     ...  \\\n",
       "0                NaN        NaN        NaN        NaN        NaN  ...   \n",
       "1                NaN        NaN        NaN        NaN        NaN  ...   \n",
       "2                NaN        0.0        NaN        NaN        NaN  ...   \n",
       "3                NaN        0.0        NaN        NaN        NaN  ...   \n",
       "4                NaN        0.0        NaN        NaN        NaN  ...   \n",
       "...              ...        ...        ...        ...        ...  ...   \n",
       "638213           NaN        NaN        NaN        NaN        NaN  ...   \n",
       "638214           NaN        NaN        NaN        NaN        NaN  ...   \n",
       "638215           NaN        NaN        NaN        NaN        NaN  ...   \n",
       "638216           NaN        NaN        NaN        NaN        NaN  ...   \n",
       "638217           NaN        NaN        NaN        NaN        NaN  ...   \n",
       "\n",
       "machineid  M_0015     M_0016     M_0017     M_0018     M_0019     M_0020     \\\n",
       "0                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4                NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "...              ...        ...        ...        ...        ...        ...   \n",
       "638213           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "638214           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "638215           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "638216           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "638217           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "machineid  M_0021     M_0022     M_0023     M_0024     \n",
       "0                NaN        NaN        NaN        NaN  \n",
       "1                NaN        NaN        NaN        NaN  \n",
       "2                NaN        NaN        NaN        NaN  \n",
       "3                NaN        NaN        NaN        NaN  \n",
       "4                NaN        NaN        NaN        NaN  \n",
       "...              ...        ...        ...        ...  \n",
       "638213           NaN        NaN        0.0        NaN  \n",
       "638214           NaN        NaN        0.0        NaN  \n",
       "638215           NaN        NaN        0.0        NaN  \n",
       "638216           NaN        NaN        0.0        NaN  \n",
       "638217           NaN        NaN        0.0        NaN  \n",
       "\n",
       "[638218 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['timestamp'] = pd.to_datetime(scores['timestamp'])\n",
    "\n",
    "scores_final = scores.pivot(index='timestamp', columns='machineid', values='risk_score').reset_index()\n",
    "\n",
    "scores_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "983c347e-7b69-40e2-b0bd-71705f2ac056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['M_0000', 'M_0001', 'M_0002', 'M_0003', 'M_0004', 'M_0005', 'M_0006',\n",
       "       'M_0007', 'M_0008', 'M_0009', 'M_0010', 'M_0011', 'M_0012', 'M_0013',\n",
       "       'M_0014', 'M_0015', 'M_0016', 'M_0017', 'M_0018', 'M_0019', 'M_0020',\n",
       "       'M_0021', 'M_0022', 'M_0023', 'M_0024'],\n",
       "      dtype='string', name='machineid')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = scores_final.columns[1:]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "565acee1-f939-4790-bd6d-2cf227bfe986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scores_final.to_csv(\"/home/ec2-user/SageMaker/capstone_try2/capstone2023/Code/forecasting/scores_table.csv\",index=False)\n",
    "# wr.s3.to_parquet(\n",
    "#     dataset=True,\n",
    "#     df=scores_final,\n",
    "#     database='capstone_v3',\n",
    "#     path=\"s3://predictive-maintenance-capstone-sn/data/score_table_v3/\",\n",
    "#     table='score_table_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7fb5d8d-24b7-45a2-b042-341102eb61bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_final['M_0000'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c214e90-fe95-4b01-94b7-7d939e733d46",
   "metadata": {},
   "source": [
    "### Now, it's time for forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75035a-5407-41aa-9aac-e01524194ab4",
   "metadata": {},
   "source": [
    "The great thing about DeepAR is that it handles NaN values pretty well ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5165eaeb-c8af-4da7-9193-1727a4d674b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import zipfile\n",
    "from dateutil.parser import parse\n",
    "import json\n",
    "from random import shuffle\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90fadab4-dab6-41b2-aef9-6b1dd4998276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/home/ec2-user/SageMaker/capstone_try2/capstone2023/Code/forecasting/scores_table.csv')\n",
    "# df = wr.athena.read_sql_query(\n",
    "#     sql=\"SELECT * FROM score_table_v3 ORDER BY timestamp\",\n",
    "#     database='capstone_v3'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "807bb413-0829-442a-ae8e-0706a3ef70c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_final['timestamp'] = pd.to_datetime(scores_final['timestamp'], unit='s')\n",
    "final_df = scores_final.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b769ab31-3899-4a72-9ed5-bcc855206c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_df.to_csv('risk_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c5329d0-c86f-485b-8d3d-5edaf1e6c63b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-11-01 00:05:32')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(final_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "948e0574-fdbc-4b5f-86a0-6710f0b89c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='timestamp'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_df['M_0000'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "561aa335-3d5b-4a0b-999c-692ef5cbe517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4254f44-d9be-45ca-83ba-4d62ffc93aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_timeseries = final_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c1a561d-0167-4adf-ba6d-b5544150c9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "for i in range(num_timeseries):\n",
    "    timeseries.append(np.trim_zeros(final_df.iloc[:, i], trim='f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd21e469-cbe3-4c80-ba35-acbdfacdc57a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2021-11-01 00:05:32   NaN\n",
       "2021-11-01 00:05:55   NaN\n",
       "2021-11-01 00:06:44   NaN\n",
       "2021-11-01 00:07:03   NaN\n",
       "2021-11-01 00:07:17   NaN\n",
       "                       ..\n",
       "2023-10-31 18:56:30   NaN\n",
       "2023-10-31 18:57:11   NaN\n",
       "2023-10-31 18:57:12   NaN\n",
       "2023-10-31 18:58:14   NaN\n",
       "2023-10-31 18:58:23   NaN\n",
       "Name: M_0000, Length: 638218, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a74ec0d-f793-48ca-ab54-98a6e153440e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in timeseries:\n",
    "#     i.plot()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a729b1e-b12b-4a99-806e-e883c8dcb2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq = '1H'\n",
    "\n",
    "prediction_length = 30\n",
    "context_length = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8cbec407-4500-47c5-8ec2-0b58d7d4dff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7830/14177154.py:1: FutureWarning: The 'freq' argument in Timestamp is deprecated and will be removed in a future version.\n",
      "  start_dataset = pd.Timestamp(\"2021-11-01 00:00:00\", freq=freq)\n",
      "/tmp/ipykernel_7830/14177154.py:2: FutureWarning: The 'freq' argument in Timestamp is deprecated and will be removed in a future version.\n",
      "  end_training = pd.Timestamp(\"2023-05-01 00:00:00\", freq=freq)\n"
     ]
    }
   ],
   "source": [
    "start_dataset = pd.Timestamp(\"2021-11-01 00:00:00\", freq=freq)\n",
    "end_training = pd.Timestamp(\"2023-05-01 00:00:00\", freq=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1df9161a-9a7d-4555-8e75-45eda2c89a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[\n",
    "            start_dataset : end_training - timedelta(days=1)\n",
    "        ].tolist()\n",
    "    }\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff3b33-b7b8-4d7b-a88a-d270494ddc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(training_data)):\n",
    "    print(training_data[i]['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f1545-838a-456d-9c6b-5506bda2ce54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "num_test_windows = 4\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset : end_training + timedelta(days=k * prediction_length)].tolist(),\n",
    "    }\n",
    "    for k in range(1, num_test_windows + 1)\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542b1bb-f759-4833-b0e0-e07c415795d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simplejson in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (3.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install simplejson\n",
    "import simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5728e41e-b82a-4939-88e3-6e574a92a757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(simplejson.dumps(d, ignore_nan=True).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8029d7eb-33a6-4def-92fc-c386f467464e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.78 s, sys: 669 ms, total: 4.45 s\n",
      "Wall time: 5.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"train.json\", training_data)\n",
    "write_dicts_to_file(\"test.json\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a94ff26-8b94-4e6c-b54a-27298e786882",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith(\"s3://\")\n",
    "    split = s3_path.split(\"/\")\n",
    "    bucket = split[2]\n",
    "    path = \"/\".join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print(\n",
    "                \"File s3://{}/{} already exists. \\nSet override to upload anyway.\\n\".format(\n",
    "                    s3_bucket, s3_path\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "        else:\n",
    "            print(\"Overwriting existing file\")\n",
    "    with open(local_file, \"rb\") as data:\n",
    "        print(\"Uploading file to {}\".format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "897385b6-9904-4336-b1f7-91dcc3ef8037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_bucket = 'predictive-maintenance-capstone-sn'\n",
    "s3_prefix = 'deepar'\n",
    "s3_data_path = 's3://{}/{}/data'.format(s3_bucket, s3_prefix)\n",
    "s3_output_path = 's3://{}/{}/output'.format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8e7b563-dea1-4cd9-b2f9-cfbe72463fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3://predictive-maintenance-capstone-sn/s3://predictive-maintenance-capstone-sn/deepar/data/train/train.json already exists. \n",
      "Set override to upload anyway.\n",
      "\n",
      "File s3://predictive-maintenance-capstone-sn/s3://predictive-maintenance-capstone-sn/deepar/data/test/test.json already exists. \n",
      "Set override to upload anyway.\n",
      "\n",
      "CPU times: user 29.6 ms, sys: 0 ns, total: 29.6 ms\n",
      "Wall time: 86.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_to_s3(\"train.json\", s3_data_path + \"/train/train.json\")\n",
    "copy_to_s3(\"test.json\", s3_data_path + \"/test/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31661b06-977d-42d3-a6d0-295112065641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2021-11-01 00:00:00\", \"target\": [null, null, null, null, null, null, null, null, null, nu...\n"
     ]
    }
   ],
   "source": [
    "s3_sample = s3.Object(s3_bucket, s3_prefix + \"/data/train/train.json\").get()[\"Body\"].read()\n",
    "\n",
    "StringVariable = s3_sample.decode(\"UTF-8\", \"ignore\")\n",
    "lines = StringVariable.split(\"\\n\")\n",
    "print(lines[0][:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91cda9ad-d33f-43d1-bb0b-133f0ab6e15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4bc3a452-6a83-4835-8046-c2b0058a4743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c4.2xlarge\",\n",
    "    base_job_name='deepar-capstone-job',\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "39c5eff3-c29d-4908-9d31-f3a53f1f8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": 75,\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f4b5aca1-8164-48ec-901f-08a9f837eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6197f6a4-2780-4c70-ba1b-a8233da84a10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: deepar-capstone-job-2023-11-28-07-23-39-743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-28 07:23:39 Starting - Starting the training job...\n",
      "2023-11-28 07:23:54 Starting - Preparing the instances for training.........\n",
      "2023-11-28 07:25:27 Downloading - Downloading input data...\n",
      "2023-11-28 07:25:56 Training - Downloading the training image.........\n",
      "2023-11-28 07:27:32 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mRunning custom environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:45 INFO 139687225485120] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:45 INFO 139687225485120] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '45', 'early_stopping_patience': '40', 'epochs': '75', 'learning_rate': '5E-4', 'mini_batch_size': '64', 'prediction_length': '30', 'time_freq': '1H'}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:45 INFO 139687225485120] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '5E-4', 'likelihood': 'student-t', 'mini_batch_size': '64', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '45', 'epochs': '75', 'prediction_length': '30', 'time_freq': '1H'}\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:45 INFO 139687225485120] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:45 INFO 139687225485120] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:45 INFO 139687225485120] random_seed is None\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:45 INFO 139687225485120] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:45 INFO 139687225485120] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] Training set statistics:\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] Integer time series\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] number of time series: 25\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] number of observations: 11929672\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] mean target length: 477186.88\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] min/mean/max target: 0.0/0.016442530859188752/8.0\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] mean abs(target): 0.016442530859188752\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] contains missing values: yes (95.9%)\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:46 INFO 139687225485120] Small number of time series. Doing 26 passes over dataset with prob 0.9846153846153847 per epoch.\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] Test set statistics:\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] Integer time series\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] number of time series: 100\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] number of observations: 54344463\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] mean target length: 543444.63\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] min/mean/max target: 0.0/0.01641009867003378/8.0\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] mean abs(target): 0.01641009867003378\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] contains missing values: yes (95.9%)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/core/date_feature_set.py:44: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  return index.weekofyear / 51.0 - 0.5\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] #memory_usage::<batchbuffer> = 577.45849609375 mb\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:51 INFO 139687225485120] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156471.1966655, \"EndTime\": 1701156472.393639, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 1196.0351467132568, \"count\": 1, \"min\": 1196.0351467132568, \"max\": 1196.0351467132568}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:52 INFO 139687225485120] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:27:52 INFO 139687225485120] #memory_usage::<model> = 74 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156472.3937194, \"EndTime\": 1701156472.8733706, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 1676.5780448913574, \"count\": 1, \"min\": 1676.5780448913574, \"max\": 1676.5780448913574}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:22 INFO 139687225485120] Epoch[0] Batch[0] avg_epoch_loss=-0.034467\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:22 INFO 139687225485120] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=-0.03446691855788231\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:23 INFO 139687225485120] Epoch[0] Batch[5] avg_epoch_loss=-0.010936\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:23 INFO 139687225485120] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=-0.010936311911791563\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:23 INFO 139687225485120] Epoch[0] Batch [5]#011Speed: 378.05 samples/sec#011loss=-0.010936\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:23 INFO 139687225485120] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156472.8734415, \"EndTime\": 1701156503.9924836, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"update.time\": {\"sum\": 31118.95728111267, \"count\": 1, \"min\": 31118.95728111267, \"max\": 31118.95728111267}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:23 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.566148519510655 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:23 INFO 139687225485120] #progress_metric: host=algo-1, completed 1.3333333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:23 INFO 139687225485120] #quality_metric: host=algo-1, epoch=0, train loss <loss>=-0.012309992220252752\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:23 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:24 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_257dca1e-f6d2-457f-a20d-bf04f7620703-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156503.992587, \"EndTime\": 1701156504.0333712, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 40.24791717529297, \"count\": 1, \"min\": 40.24791717529297, \"max\": 40.24791717529297}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:51 INFO 139687225485120] Epoch[1] Batch[0] avg_epoch_loss=0.000734\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:51 INFO 139687225485120] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=0.0007337660063058138\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:52 INFO 139687225485120] Epoch[1] Batch[5] avg_epoch_loss=-0.007508\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:52 INFO 139687225485120] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=-0.007507622358389199\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:52 INFO 139687225485120] Epoch[1] Batch [5]#011Speed: 389.20 samples/sec#011loss=-0.007508\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:52 INFO 139687225485120] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156504.0334516, \"EndTime\": 1701156532.9542682, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28920.75753211975, \"count\": 1, \"min\": 28920.75753211975, \"max\": 28920.75753211975}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:52 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.988293519155864 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:52 INFO 139687225485120] #progress_metric: host=algo-1, completed 2.6666666666666665 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:52 INFO 139687225485120] #quality_metric: host=algo-1, epoch=1, train loss <loss>=-0.011975692748092116\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:28:52 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:20 INFO 139687225485120] Epoch[2] Batch[0] avg_epoch_loss=0.008697\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:20 INFO 139687225485120] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=0.008697155863046646\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:20 INFO 139687225485120] Epoch[2] Batch[5] avg_epoch_loss=-0.021256\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:20 INFO 139687225485120] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=-0.02125637015948693\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:20 INFO 139687225485120] Epoch[2] Batch [5]#011Speed: 374.58 samples/sec#011loss=-0.021256\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:21 INFO 139687225485120] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156532.9543571, \"EndTime\": 1701156561.7701685, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28815.263748168945, \"count\": 1, \"min\": 28815.263748168945, \"max\": 28815.263748168945}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:21 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.036829805527503 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:21 INFO 139687225485120] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:21 INFO 139687225485120] #quality_metric: host=algo-1, epoch=2, train loss <loss>=-0.019376215152442457\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:21 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:21 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_3d9acd36-f05d-436d-a0a6-5540dd25336c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156561.7702632, \"EndTime\": 1701156561.8088195, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 38.021087646484375, \"count\": 1, \"min\": 38.021087646484375, \"max\": 38.021087646484375}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:48 INFO 139687225485120] Epoch[3] Batch[0] avg_epoch_loss=-0.048973\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:48 INFO 139687225485120] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=-0.048972710967063904\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:49 INFO 139687225485120] Epoch[3] Batch[5] avg_epoch_loss=-0.049641\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:49 INFO 139687225485120] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=-0.04964085419972738\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:49 INFO 139687225485120] Epoch[3] Batch [5]#011Speed: 374.72 samples/sec#011loss=-0.049641\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:50 INFO 139687225485120] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156561.8088958, \"EndTime\": 1701156590.6566808, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28847.72801399231, \"count\": 1, \"min\": 28847.72801399231, \"max\": 28847.72801399231}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:50 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.700051208840122 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:50 INFO 139687225485120] #progress_metric: host=algo-1, completed 5.333333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:50 INFO 139687225485120] #quality_metric: host=algo-1, epoch=3, train loss <loss>=-0.043926005018875\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:50 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:29:50 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_6d4ecb96-29f3-4d47-87c4-520a1ba25e17-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156590.6567767, \"EndTime\": 1701156590.682865, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 25.522232055664062, \"count\": 1, \"min\": 25.522232055664062, \"max\": 25.522232055664062}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:17 INFO 139687225485120] Epoch[4] Batch[0] avg_epoch_loss=-0.053242\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:17 INFO 139687225485120] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=-0.053241826593875885\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:18 INFO 139687225485120] Epoch[4] Batch[5] avg_epoch_loss=-0.020684\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:18 INFO 139687225485120] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=-0.02068448594460885\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:18 INFO 139687225485120] Epoch[4] Batch [5]#011Speed: 379.49 samples/sec#011loss=-0.020684\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:19 INFO 139687225485120] Epoch[4] Batch[10] avg_epoch_loss=-0.022769\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:19 INFO 139687225485120] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=-0.02527011192869395\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:19 INFO 139687225485120] Epoch[4] Batch [10]#011Speed: 180.32 samples/sec#011loss=-0.025270\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:19 INFO 139687225485120] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156590.6829498, \"EndTime\": 1701156619.9659536, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29282.936573028564, \"count\": 1, \"min\": 29282.936573028564, \"max\": 29282.936573028564}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:19 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.367850118331596 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:19 INFO 139687225485120] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:19 INFO 139687225485120] #quality_metric: host=algo-1, epoch=4, train loss <loss>=-0.022768861391920258\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:19 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:47 INFO 139687225485120] Epoch[5] Batch[0] avg_epoch_loss=-0.010186\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:47 INFO 139687225485120] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=-0.010186152532696724\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:47 INFO 139687225485120] Epoch[5] Batch[5] avg_epoch_loss=-0.037957\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:47 INFO 139687225485120] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=-0.037957384095837675\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:47 INFO 139687225485120] Epoch[5] Batch [5]#011Speed: 358.62 samples/sec#011loss=-0.037957\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:48 INFO 139687225485120] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156619.9660816, \"EndTime\": 1701156648.80072, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28834.171533584595, \"count\": 1, \"min\": 28834.171533584595, \"max\": 28834.171533584595}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:48 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.640888817757105 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:48 INFO 139687225485120] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:48 INFO 139687225485120] #quality_metric: host=algo-1, epoch=5, train loss <loss>=-0.031569536123424766\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:30:48 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:15 INFO 139687225485120] Epoch[6] Batch[0] avg_epoch_loss=-0.069658\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:15 INFO 139687225485120] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=-0.06965846568346024\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:16 INFO 139687225485120] Epoch[6] Batch[5] avg_epoch_loss=-0.046621\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:16 INFO 139687225485120] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=-0.046620709666361414\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:16 INFO 139687225485120] Epoch[6] Batch [5]#011Speed: 343.74 samples/sec#011loss=-0.046621\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] Epoch[6] Batch[10] avg_epoch_loss=-0.051283\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=-0.05687739923596382\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] Epoch[6] Batch [10]#011Speed: 220.10 samples/sec#011loss=-0.056877\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156648.800815, \"EndTime\": 1701156678.3679807, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29566.605806350708, \"count\": 1, \"min\": 29566.605806350708, \"max\": 29566.605806350708}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.88268489776817 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] #progress_metric: host=algo-1, completed 9.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] #quality_metric: host=algo-1, epoch=6, train loss <loss>=-0.05128284128890796\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:18 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_396660a2-556d-465c-9f9a-25c2551de1bc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156678.368092, \"EndTime\": 1701156678.4098895, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 41.28575325012207, \"count\": 1, \"min\": 41.28575325012207, \"max\": 41.28575325012207}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:43 INFO 139687225485120] Epoch[7] Batch[0] avg_epoch_loss=-0.079190\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:43 INFO 139687225485120] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=-0.07919038087129593\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:44 INFO 139687225485120] Epoch[7] Batch[5] avg_epoch_loss=-0.047307\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:44 INFO 139687225485120] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=-0.04730738544215759\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:44 INFO 139687225485120] Epoch[7] Batch [5]#011Speed: 343.48 samples/sec#011loss=-0.047307\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:47 INFO 139687225485120] Epoch[7] Batch[10] avg_epoch_loss=-0.047627\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:47 INFO 139687225485120] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=-0.048010251671075824\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:47 INFO 139687225485120] Epoch[7] Batch [10]#011Speed: 101.98 samples/sec#011loss=-0.048010\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:47 INFO 139687225485120] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156678.409969, \"EndTime\": 1701156707.928288, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29518.26000213623, \"count\": 1, \"min\": 29518.26000213623, \"max\": 29518.26000213623}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:47 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=23.375280369390957 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:47 INFO 139687225485120] #progress_metric: host=algo-1, completed 10.666666666666666 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:47 INFO 139687225485120] #quality_metric: host=algo-1, epoch=7, train loss <loss>=-0.04762687009166588\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:31:47 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:15 INFO 139687225485120] Epoch[8] Batch[0] avg_epoch_loss=-0.036004\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:15 INFO 139687225485120] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=-0.03600402548909187\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:16 INFO 139687225485120] Epoch[8] Batch[5] avg_epoch_loss=-0.033731\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:16 INFO 139687225485120] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=-0.03373143635690212\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:16 INFO 139687225485120] Epoch[8] Batch [5]#011Speed: 348.56 samples/sec#011loss=-0.033731\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:17 INFO 139687225485120] Epoch[8] Batch[10] avg_epoch_loss=-0.050791\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:17 INFO 139687225485120] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=-0.07126322807744145\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:17 INFO 139687225485120] Epoch[8] Batch [10]#011Speed: 276.33 samples/sec#011loss=-0.071263\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:17 INFO 139687225485120] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156707.9283571, \"EndTime\": 1701156737.7782025, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29849.274158477783, \"count\": 1, \"min\": 29849.274158477783, \"max\": 29849.274158477783}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:17 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.474457318137198 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:17 INFO 139687225485120] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:17 INFO 139687225485120] #quality_metric: host=algo-1, epoch=8, train loss <loss>=-0.050791341684420004\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:17 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:45 INFO 139687225485120] Epoch[9] Batch[0] avg_epoch_loss=-0.068555\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:45 INFO 139687225485120] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=-0.06855525821447372\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] Epoch[9] Batch[5] avg_epoch_loss=-0.053871\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=-0.05387146181116501\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] Epoch[9] Batch [5]#011Speed: 373.89 samples/sec#011loss=-0.053871\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156737.7783012, \"EndTime\": 1701156766.9015286, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29122.64895439148, \"count\": 1, \"min\": 29122.64895439148, \"max\": 29122.64895439148}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.877144319704243 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] #quality_metric: host=algo-1, epoch=9, train loss <loss>=-0.05471094585955143\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:32:46 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_13a6a60e-0ee6-46ec-865d-b9027d124871-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156766.901599, \"EndTime\": 1701156766.9277565, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 25.55990219116211, \"count\": 1, \"min\": 25.55990219116211, \"max\": 25.55990219116211}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:13 INFO 139687225485120] Epoch[10] Batch[0] avg_epoch_loss=-0.031494\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:13 INFO 139687225485120] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=-0.03149362653493881\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:14 INFO 139687225485120] Epoch[10] Batch[5] avg_epoch_loss=-0.058919\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:14 INFO 139687225485120] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=-0.05891873066624006\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:14 INFO 139687225485120] Epoch[10] Batch [5]#011Speed: 375.98 samples/sec#011loss=-0.058919\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] Epoch[10] Batch[10] avg_epoch_loss=-0.057684\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=-0.05620338842272758\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] Epoch[10] Batch [10]#011Speed: 166.85 samples/sec#011loss=-0.056203\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156766.9278264, \"EndTime\": 1701156796.3240473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29396.158695220947, \"count\": 1, \"min\": 29396.158695220947, \"max\": 29396.158695220947}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.315732829980817 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] #progress_metric: host=algo-1, completed 14.666666666666666 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] #quality_metric: host=algo-1, epoch=10, train loss <loss>=-0.057684484191916206\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:16 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_9432676b-0068-471c-958a-86bca4f62043-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156796.3241556, \"EndTime\": 1701156796.3510432, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 26.351213455200195, \"count\": 1, \"min\": 26.351213455200195, \"max\": 26.351213455200195}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:43 INFO 139687225485120] Epoch[11] Batch[0] avg_epoch_loss=-0.050063\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:43 INFO 139687225485120] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=-0.05006323754787445\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:44 INFO 139687225485120] Epoch[11] Batch[5] avg_epoch_loss=-0.059062\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:44 INFO 139687225485120] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=-0.059062087520336114\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:44 INFO 139687225485120] Epoch[11] Batch [5]#011Speed: 351.12 samples/sec#011loss=-0.059062\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:45 INFO 139687225485120] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156796.351117, \"EndTime\": 1701156825.3921854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29041.006803512573, \"count\": 1, \"min\": 29041.006803512573, \"max\": 29041.006803512573}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:45 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.452324439657506 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:45 INFO 139687225485120] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:45 INFO 139687225485120] #quality_metric: host=algo-1, epoch=11, train loss <loss>=-0.06957300617359578\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:45 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:33:45 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_7511de9a-6ddc-459a-82c0-859e9cfce5e6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156825.392282, \"EndTime\": 1701156825.4185688, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 25.707721710205078, \"count\": 1, \"min\": 25.707721710205078, \"max\": 25.707721710205078}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:11 INFO 139687225485120] Epoch[12] Batch[0] avg_epoch_loss=-0.011513\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:11 INFO 139687225485120] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=-0.01151280477643013\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:12 INFO 139687225485120] Epoch[12] Batch[5] avg_epoch_loss=-0.083769\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:12 INFO 139687225485120] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=-0.08376910102864106\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:12 INFO 139687225485120] Epoch[12] Batch [5]#011Speed: 345.05 samples/sec#011loss=-0.083769\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:14 INFO 139687225485120] Epoch[12] Batch[10] avg_epoch_loss=-0.059511\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:14 INFO 139687225485120] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=-0.030400936678051948\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:14 INFO 139687225485120] Epoch[12] Batch [10]#011Speed: 161.89 samples/sec#011loss=-0.030401\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:14 INFO 139687225485120] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156825.4186487, \"EndTime\": 1701156854.8579786, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29439.265966415405, \"count\": 1, \"min\": 29439.265966415405, \"max\": 29439.265966415405}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:14 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.452911285255126 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:14 INFO 139687225485120] #progress_metric: host=algo-1, completed 17.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:14 INFO 139687225485120] #quality_metric: host=algo-1, epoch=12, train loss <loss>=-0.05951084450564601\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:14 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:42 INFO 139687225485120] Epoch[13] Batch[0] avg_epoch_loss=-0.088171\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:42 INFO 139687225485120] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=-0.0881713256239891\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:43 INFO 139687225485120] Epoch[13] Batch[5] avg_epoch_loss=-0.061735\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:43 INFO 139687225485120] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=-0.061735390685498714\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:43 INFO 139687225485120] Epoch[13] Batch [5]#011Speed: 344.21 samples/sec#011loss=-0.061735\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:43 INFO 139687225485120] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156854.8580663, \"EndTime\": 1701156883.9037547, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29045.157194137573, \"count\": 1, \"min\": 29045.157194137573, \"max\": 29045.157194137573}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:43 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.001693925529956 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:43 INFO 139687225485120] #progress_metric: host=algo-1, completed 18.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:43 INFO 139687225485120] #quality_metric: host=algo-1, epoch=13, train loss <loss>=-0.05949874352663755\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:34:43 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:11 INFO 139687225485120] Epoch[14] Batch[0] avg_epoch_loss=-0.046271\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:11 INFO 139687225485120] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=-0.04627126827836037\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:12 INFO 139687225485120] Epoch[14] Batch[5] avg_epoch_loss=-0.057842\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:12 INFO 139687225485120] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=-0.05784193550546964\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:12 INFO 139687225485120] Epoch[14] Batch [5]#011Speed: 359.11 samples/sec#011loss=-0.057842\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:13 INFO 139687225485120] Epoch[14] Batch[10] avg_epoch_loss=-0.061110\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:13 INFO 139687225485120] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=-0.06503218626603484\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:13 INFO 139687225485120] Epoch[14] Batch [10]#011Speed: 216.43 samples/sec#011loss=-0.065032\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:13 INFO 139687225485120] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156883.9038424, \"EndTime\": 1701156913.6847153, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29780.26270866394, \"count\": 1, \"min\": 29780.26270866394, \"max\": 29780.26270866394}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:13 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.860034360345157 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:13 INFO 139687225485120] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:13 INFO 139687225485120] #quality_metric: host=algo-1, epoch=14, train loss <loss>=-0.06111023130572655\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:13 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:41 INFO 139687225485120] Epoch[15] Batch[0] avg_epoch_loss=-0.055412\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:41 INFO 139687225485120] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=-0.05541158840060234\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:41 INFO 139687225485120] Epoch[15] Batch[5] avg_epoch_loss=-0.044054\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:41 INFO 139687225485120] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=-0.04405367669338981\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:41 INFO 139687225485120] Epoch[15] Batch [5]#011Speed: 375.51 samples/sec#011loss=-0.044054\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:42 INFO 139687225485120] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156913.6847878, \"EndTime\": 1701156942.7020693, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29016.720056533813, \"count\": 1, \"min\": 29016.720056533813, \"max\": 29016.720056533813}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:42 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.125660122353747 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:42 INFO 139687225485120] #progress_metric: host=algo-1, completed 21.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:42 INFO 139687225485120] #quality_metric: host=algo-1, epoch=15, train loss <loss>=-0.061338487546890974\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:35:42 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:10 INFO 139687225485120] Epoch[16] Batch[0] avg_epoch_loss=-0.070591\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:10 INFO 139687225485120] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=-0.07059149444103241\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:10 INFO 139687225485120] Epoch[16] Batch[5] avg_epoch_loss=-0.076923\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:10 INFO 139687225485120] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=-0.07692254583040874\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:10 INFO 139687225485120] Epoch[16] Batch [5]#011Speed: 378.49 samples/sec#011loss=-0.076923\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:11 INFO 139687225485120] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156942.7021527, \"EndTime\": 1701156971.7042665, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29001.526594161987, \"count\": 1, \"min\": 29001.526594161987, \"max\": 29001.526594161987}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:11 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.17121054732788 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:11 INFO 139687225485120] #progress_metric: host=algo-1, completed 22.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:11 INFO 139687225485120] #quality_metric: host=algo-1, epoch=16, train loss <loss>=-0.07283472754061222\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:11 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:11 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_95509619-eee8-4b9b-a9c5-7b5a131ba0bf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156971.7043493, \"EndTime\": 1701156971.7302175, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 25.2838134765625, \"count\": 1, \"min\": 25.2838134765625, \"max\": 25.2838134765625}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:39 INFO 139687225485120] Epoch[17] Batch[0] avg_epoch_loss=-0.093391\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:39 INFO 139687225485120] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=-0.09339073300361633\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:40 INFO 139687225485120] Epoch[17] Batch[5] avg_epoch_loss=-0.076504\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:40 INFO 139687225485120] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=-0.0765035655349493\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:40 INFO 139687225485120] Epoch[17] Batch [5]#011Speed: 379.33 samples/sec#011loss=-0.076504\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:40 INFO 139687225485120] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701156971.7302933, \"EndTime\": 1701157000.8943207, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29163.968086242676, \"count\": 1, \"min\": 29163.968086242676, \"max\": 29163.968086242676}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:40 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.841930532571563 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:40 INFO 139687225485120] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:40 INFO 139687225485120] #quality_metric: host=algo-1, epoch=17, train loss <loss>=-0.062410570494830606\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:36:40 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:08 INFO 139687225485120] Epoch[18] Batch[0] avg_epoch_loss=-0.078293\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:08 INFO 139687225485120] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=-0.07829282432794571\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:09 INFO 139687225485120] Epoch[18] Batch[5] avg_epoch_loss=-0.075066\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:09 INFO 139687225485120] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=-0.07506574255724748\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:09 INFO 139687225485120] Epoch[18] Batch [5]#011Speed: 400.18 samples/sec#011loss=-0.075066\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:09 INFO 139687225485120] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157000.894406, \"EndTime\": 1701157029.9228473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29027.89282798767, \"count\": 1, \"min\": 29027.89282798767, \"max\": 29027.89282798767}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:09 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.083076863940484 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:09 INFO 139687225485120] #progress_metric: host=algo-1, completed 25.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:09 INFO 139687225485120] #quality_metric: host=algo-1, epoch=18, train loss <loss>=-0.067554631549865\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:09 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:37 INFO 139687225485120] Epoch[19] Batch[0] avg_epoch_loss=-0.139820\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:37 INFO 139687225485120] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=-0.13981974124908447\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:38 INFO 139687225485120] Epoch[19] Batch[5] avg_epoch_loss=-0.089544\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:38 INFO 139687225485120] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=-0.08954413095489144\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:38 INFO 139687225485120] Epoch[19] Batch [5]#011Speed: 374.26 samples/sec#011loss=-0.089544\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:38 INFO 139687225485120] processed a total of 577 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157029.922936, \"EndTime\": 1701157058.999816, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29076.28059387207, \"count\": 1, \"min\": 29076.28059387207, \"max\": 29076.28059387207}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:38 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=19.84425944776178 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:39 INFO 139687225485120] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:39 INFO 139687225485120] #quality_metric: host=algo-1, epoch=19, train loss <loss>=-0.08372357627376914\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:39 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:37:39 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_b9e3dbb5-35f1-4b75-b390-c402f20af67a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157058.9999146, \"EndTime\": 1701157059.04232, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 41.81718826293945, \"count\": 1, \"min\": 41.81718826293945, \"max\": 41.81718826293945}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:06 INFO 139687225485120] Epoch[20] Batch[0] avg_epoch_loss=-0.065451\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:06 INFO 139687225485120] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=-0.06545144319534302\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:07 INFO 139687225485120] Epoch[20] Batch[5] avg_epoch_loss=-0.067513\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:07 INFO 139687225485120] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=-0.06751302443444729\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:07 INFO 139687225485120] Epoch[20] Batch [5]#011Speed: 357.28 samples/sec#011loss=-0.067513\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:08 INFO 139687225485120] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157059.0423963, \"EndTime\": 1701157088.248048, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29205.596923828125, \"count\": 1, \"min\": 29205.596923828125, \"max\": 29205.596923828125}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:08 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.3656696973137 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:08 INFO 139687225485120] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:08 INFO 139687225485120] #quality_metric: host=algo-1, epoch=20, train loss <loss>=-0.07224196866154671\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:08 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:35 INFO 139687225485120] Epoch[21] Batch[0] avg_epoch_loss=-0.104447\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:35 INFO 139687225485120] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=-0.1044473797082901\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:36 INFO 139687225485120] Epoch[21] Batch[5] avg_epoch_loss=-0.103199\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:36 INFO 139687225485120] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=-0.10319925223787625\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:36 INFO 139687225485120] Epoch[21] Batch [5]#011Speed: 360.52 samples/sec#011loss=-0.103199\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:37 INFO 139687225485120] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157088.2481523, \"EndTime\": 1701157117.3041668, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29055.49192428589, \"count\": 1, \"min\": 29055.49192428589, \"max\": 29055.49192428589}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:37 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.957900556424875 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:37 INFO 139687225485120] #progress_metric: host=algo-1, completed 29.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:37 INFO 139687225485120] #quality_metric: host=algo-1, epoch=21, train loss <loss>=-0.09495875984430313\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:37 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:38:37 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_6203aecb-d977-4444-9a03-af9af600c1cb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157117.30424, \"EndTime\": 1701157117.3302917, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 25.468826293945312, \"count\": 1, \"min\": 25.468826293945312, \"max\": 25.468826293945312}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:04 INFO 139687225485120] Epoch[22] Batch[0] avg_epoch_loss=-0.159546\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:04 INFO 139687225485120] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=-0.15954597294330597\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:05 INFO 139687225485120] Epoch[22] Batch[5] avg_epoch_loss=-0.092178\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:05 INFO 139687225485120] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=-0.09217802435159683\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:05 INFO 139687225485120] Epoch[22] Batch [5]#011Speed: 380.94 samples/sec#011loss=-0.092178\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:06 INFO 139687225485120] Epoch[22] Batch[10] avg_epoch_loss=-0.084538\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:06 INFO 139687225485120] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=-0.07536962702870369\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:06 INFO 139687225485120] Epoch[22] Batch [10]#011Speed: 179.40 samples/sec#011loss=-0.075370\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:06 INFO 139687225485120] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157117.330365, \"EndTime\": 1701157146.8372035, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29506.77800178528, \"count\": 1, \"min\": 29506.77800178528, \"max\": 29506.77800178528}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:06 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.85929564070151 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:06 INFO 139687225485120] #progress_metric: host=algo-1, completed 30.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:06 INFO 139687225485120] #quality_metric: host=algo-1, epoch=22, train loss <loss>=-0.08453784375028177\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:06 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:33 INFO 139687225485120] Epoch[23] Batch[0] avg_epoch_loss=-0.123737\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:33 INFO 139687225485120] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=-0.12373737245798111\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:34 INFO 139687225485120] Epoch[23] Batch[5] avg_epoch_loss=-0.090486\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:34 INFO 139687225485120] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=-0.09048617755373319\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:34 INFO 139687225485120] Epoch[23] Batch [5]#011Speed: 366.16 samples/sec#011loss=-0.090486\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] Epoch[23] Batch[10] avg_epoch_loss=-0.121268\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=-0.15820666700601577\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] Epoch[23] Batch [10]#011Speed: 181.88 samples/sec#011loss=-0.158207\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157146.8372893, \"EndTime\": 1701157176.269817, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29431.967973709106, \"count\": 1, \"min\": 29431.967973709106, \"max\": 29431.967973709106}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.254625195431878 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] #quality_metric: host=algo-1, epoch=23, train loss <loss>=-0.12126821821386163\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:39:36 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_746b00ca-7d74-49c0-a21d-495c16e6bb45-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157176.2698941, \"EndTime\": 1701157176.2962651, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 25.74014663696289, \"count\": 1, \"min\": 25.74014663696289, \"max\": 25.74014663696289}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:03 INFO 139687225485120] Epoch[24] Batch[0] avg_epoch_loss=-0.106935\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:03 INFO 139687225485120] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=-0.10693474858999252\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:04 INFO 139687225485120] Epoch[24] Batch[5] avg_epoch_loss=-0.061098\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:04 INFO 139687225485120] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=-0.06109788858642181\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:04 INFO 139687225485120] Epoch[24] Batch [5]#011Speed: 348.32 samples/sec#011loss=-0.061098\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:05 INFO 139687225485120] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157176.2963438, \"EndTime\": 1701157205.4541028, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29157.70196914673, \"count\": 1, \"min\": 29157.70196914673, \"max\": 29157.70196914673}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:05 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.949514216091604 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:05 INFO 139687225485120] #progress_metric: host=algo-1, completed 33.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:05 INFO 139687225485120] #quality_metric: host=algo-1, epoch=24, train loss <loss>=-0.06885734205134213\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:05 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:32 INFO 139687225485120] Epoch[25] Batch[0] avg_epoch_loss=-0.051344\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:32 INFO 139687225485120] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=-0.05134446546435356\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:33 INFO 139687225485120] Epoch[25] Batch[5] avg_epoch_loss=-0.060544\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:33 INFO 139687225485120] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=-0.06054358595671753\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:33 INFO 139687225485120] Epoch[25] Batch [5]#011Speed: 395.85 samples/sec#011loss=-0.060544\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:34 INFO 139687225485120] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157205.4541905, \"EndTime\": 1701157234.2066233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28751.853704452515, \"count\": 1, \"min\": 28751.853704452515, \"max\": 28751.853704452515}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:34 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.08543087802378 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:34 INFO 139687225485120] #progress_metric: host=algo-1, completed 34.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:34 INFO 139687225485120] #quality_metric: host=algo-1, epoch=25, train loss <loss>=-0.057852646755054596\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:40:34 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:00 INFO 139687225485120] Epoch[26] Batch[0] avg_epoch_loss=-0.063687\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:00 INFO 139687225485120] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=-0.0636868104338646\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:01 INFO 139687225485120] Epoch[26] Batch[5] avg_epoch_loss=-0.090705\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:01 INFO 139687225485120] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=-0.09070455903808276\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:01 INFO 139687225485120] Epoch[26] Batch [5]#011Speed: 356.99 samples/sec#011loss=-0.090705\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:03 INFO 139687225485120] Epoch[26] Batch[10] avg_epoch_loss=-0.072690\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:03 INFO 139687225485120] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=-0.05107265934348106\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:03 INFO 139687225485120] Epoch[26] Batch [10]#011Speed: 165.78 samples/sec#011loss=-0.051073\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:03 INFO 139687225485120] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157234.2067158, \"EndTime\": 1701157263.6990302, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29491.809368133545, \"count\": 1, \"min\": 29491.809368133545, \"max\": 29491.809368133545}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:03 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.00601870067119 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:03 INFO 139687225485120] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:03 INFO 139687225485120] #quality_metric: host=algo-1, epoch=26, train loss <loss>=-0.07269005917690018\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:03 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:29 INFO 139687225485120] Epoch[27] Batch[0] avg_epoch_loss=-0.088438\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:29 INFO 139687225485120] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=-0.08843786269426346\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:30 INFO 139687225485120] Epoch[27] Batch[5] avg_epoch_loss=-0.070692\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:30 INFO 139687225485120] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=-0.0706918320308129\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:30 INFO 139687225485120] Epoch[27] Batch [5]#011Speed: 398.72 samples/sec#011loss=-0.070692\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:32 INFO 139687225485120] Epoch[27] Batch[10] avg_epoch_loss=-0.094231\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:32 INFO 139687225485120] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=-0.12247862964868546\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:32 INFO 139687225485120] Epoch[27] Batch [10]#011Speed: 160.80 samples/sec#011loss=-0.122479\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:32 INFO 139687225485120] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157263.6991153, \"EndTime\": 1701157292.747637, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29048.025608062744, \"count\": 1, \"min\": 29048.025608062744, \"max\": 29048.025608062744}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:32 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.686477593859337 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:32 INFO 139687225485120] #progress_metric: host=algo-1, completed 37.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:32 INFO 139687225485120] #quality_metric: host=algo-1, epoch=27, train loss <loss>=-0.09423128549348224\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:32 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:59 INFO 139687225485120] Epoch[28] Batch[0] avg_epoch_loss=-0.059876\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:41:59 INFO 139687225485120] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=-0.05987566336989403\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:00 INFO 139687225485120] Epoch[28] Batch[5] avg_epoch_loss=-0.092550\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:00 INFO 139687225485120] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=-0.09255040002365907\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:00 INFO 139687225485120] Epoch[28] Batch [5]#011Speed: 374.29 samples/sec#011loss=-0.092550\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:01 INFO 139687225485120] Epoch[28] Batch[10] avg_epoch_loss=-0.129694\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:01 INFO 139687225485120] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=-0.17426553815603257\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:01 INFO 139687225485120] Epoch[28] Batch [10]#011Speed: 197.86 samples/sec#011loss=-0.174266\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:01 INFO 139687225485120] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157292.7477133, \"EndTime\": 1701157321.985533, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29237.290620803833, \"count\": 1, \"min\": 29237.290620803833, \"max\": 29237.290620803833}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:01 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.19759673081765 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:01 INFO 139687225485120] #progress_metric: host=algo-1, completed 38.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:01 INFO 139687225485120] #quality_metric: host=algo-1, epoch=28, train loss <loss>=-0.12969364462928337\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:01 INFO 139687225485120] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:02 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/state_e02275d2-93f7-411b-acb4-96c86af2e4d5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157321.985607, \"EndTime\": 1701157322.013198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 27.036190032958984, \"count\": 1, \"min\": 27.036190032958984, \"max\": 27.036190032958984}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:29 INFO 139687225485120] Epoch[29] Batch[0] avg_epoch_loss=-0.043990\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:29 INFO 139687225485120] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=-0.04399025812745094\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:29 INFO 139687225485120] Epoch[29] Batch[5] avg_epoch_loss=-0.008389\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:29 INFO 139687225485120] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=-0.008388908521737903\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:29 INFO 139687225485120] Epoch[29] Batch [5]#011Speed: 332.99 samples/sec#011loss=-0.008389\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:31 INFO 139687225485120] Epoch[29] Batch[10] avg_epoch_loss=-0.007437\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:31 INFO 139687225485120] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=-0.006293974537402392\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:31 INFO 139687225485120] Epoch[29] Batch [10]#011Speed: 177.79 samples/sec#011loss=-0.006294\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:31 INFO 139687225485120] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157322.0132716, \"EndTime\": 1701157351.7789168, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29765.583992004395, \"count\": 1, \"min\": 29765.583992004395, \"max\": 29765.583992004395}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:31 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.837171515502078 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:31 INFO 139687225485120] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:31 INFO 139687225485120] #quality_metric: host=algo-1, epoch=29, train loss <loss>=-0.007436665801585398\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:31 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:59 INFO 139687225485120] Epoch[30] Batch[0] avg_epoch_loss=-0.031121\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:42:59 INFO 139687225485120] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=-0.031121117994189262\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:00 INFO 139687225485120] Epoch[30] Batch[5] avg_epoch_loss=-0.047410\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:00 INFO 139687225485120] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=-0.047410050445857145\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:00 INFO 139687225485120] Epoch[30] Batch [5]#011Speed: 351.48 samples/sec#011loss=-0.047410\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:01 INFO 139687225485120] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157351.779055, \"EndTime\": 1701157381.0676541, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29288.097858428955, \"count\": 1, \"min\": 29288.097858428955, \"max\": 29288.097858428955}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:01 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.681065298120412 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:01 INFO 139687225485120] #progress_metric: host=algo-1, completed 41.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:01 INFO 139687225485120] #quality_metric: host=algo-1, epoch=30, train loss <loss>=-0.053333120257593694\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:01 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:28 INFO 139687225485120] Epoch[31] Batch[0] avg_epoch_loss=-0.064523\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:28 INFO 139687225485120] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=-0.0645228773355484\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:29 INFO 139687225485120] Epoch[31] Batch[5] avg_epoch_loss=-0.056179\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:29 INFO 139687225485120] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=-0.05617866354684035\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:29 INFO 139687225485120] Epoch[31] Batch [5]#011Speed: 365.95 samples/sec#011loss=-0.056179\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:30 INFO 139687225485120] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157381.0677462, \"EndTime\": 1701157410.2681684, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29199.880838394165, \"count\": 1, \"min\": 29199.880838394165, \"max\": 29199.880838394165}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:30 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.68493856657394 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:30 INFO 139687225485120] #progress_metric: host=algo-1, completed 42.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:30 INFO 139687225485120] #quality_metric: host=algo-1, epoch=31, train loss <loss>=-0.006308123824419453\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:30 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:57 INFO 139687225485120] Epoch[32] Batch[0] avg_epoch_loss=-0.048864\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:57 INFO 139687225485120] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=-0.04886382073163986\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:58 INFO 139687225485120] Epoch[32] Batch[5] avg_epoch_loss=-0.064618\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:58 INFO 139687225485120] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=-0.06461789769430955\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:58 INFO 139687225485120] Epoch[32] Batch [5]#011Speed: 398.66 samples/sec#011loss=-0.064618\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:59 INFO 139687225485120] Epoch[32] Batch[10] avg_epoch_loss=-0.052720\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:59 INFO 139687225485120] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=-0.03844306841492653\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:59 INFO 139687225485120] Epoch[32] Batch [10]#011Speed: 276.19 samples/sec#011loss=-0.038443\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:59 INFO 139687225485120] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157410.2682424, \"EndTime\": 1701157439.552373, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29283.563137054443, \"count\": 1, \"min\": 29283.563137054443, \"max\": 29283.563137054443}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:59 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.957616226242063 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:59 INFO 139687225485120] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:59 INFO 139687225485120] #quality_metric: host=algo-1, epoch=32, train loss <loss>=-0.052720248021862724\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:43:59 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:26 INFO 139687225485120] Epoch[33] Batch[0] avg_epoch_loss=-0.133003\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:26 INFO 139687225485120] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=-0.13300290703773499\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:27 INFO 139687225485120] Epoch[33] Batch[5] avg_epoch_loss=-0.073069\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:27 INFO 139687225485120] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=-0.07306878800348689\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:27 INFO 139687225485120] Epoch[33] Batch [5]#011Speed: 369.11 samples/sec#011loss=-0.073069\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:28 INFO 139687225485120] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157439.5524614, \"EndTime\": 1701157468.6736434, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29120.696306228638, \"count\": 1, \"min\": 29120.696306228638, \"max\": 29120.696306228638}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:28 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.569472827146534 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:28 INFO 139687225485120] #progress_metric: host=algo-1, completed 45.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:28 INFO 139687225485120] #quality_metric: host=algo-1, epoch=33, train loss <loss>=-0.07623781964648516\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:28 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:56 INFO 139687225485120] Epoch[34] Batch[0] avg_epoch_loss=0.002672\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:56 INFO 139687225485120] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=0.0026720850728452206\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:56 INFO 139687225485120] Epoch[34] Batch[5] avg_epoch_loss=-0.058635\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:56 INFO 139687225485120] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=-0.05863466649316251\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:56 INFO 139687225485120] Epoch[34] Batch [5]#011Speed: 353.42 samples/sec#011loss=-0.058635\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:57 INFO 139687225485120] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157468.6737356, \"EndTime\": 1701157497.816368, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29142.06099510193, \"count\": 1, \"min\": 29142.06099510193, \"max\": 29142.06099510193}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:57 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.789711841129556 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:57 INFO 139687225485120] #progress_metric: host=algo-1, completed 46.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:57 INFO 139687225485120] #quality_metric: host=algo-1, epoch=34, train loss <loss>=-0.06424512066878378\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:44:57 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:25 INFO 139687225485120] Epoch[35] Batch[0] avg_epoch_loss=-0.053517\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:25 INFO 139687225485120] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=-0.05351680889725685\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:26 INFO 139687225485120] Epoch[35] Batch[5] avg_epoch_loss=-0.081336\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:26 INFO 139687225485120] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=-0.08133555079499881\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:26 INFO 139687225485120] Epoch[35] Batch [5]#011Speed: 357.13 samples/sec#011loss=-0.081336\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:27 INFO 139687225485120] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157497.8164618, \"EndTime\": 1701157527.0151591, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29198.184490203857, \"count\": 1, \"min\": 29198.184490203857, \"max\": 29198.184490203857}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:27 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.884818692097397 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:27 INFO 139687225485120] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:27 INFO 139687225485120] #quality_metric: host=algo-1, epoch=35, train loss <loss>=-0.06627653446048498\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:27 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:54 INFO 139687225485120] Epoch[36] Batch[0] avg_epoch_loss=-0.102818\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:54 INFO 139687225485120] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=-0.10281797498464584\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:55 INFO 139687225485120] Epoch[36] Batch[5] avg_epoch_loss=-0.075204\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:55 INFO 139687225485120] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=-0.07520424388349056\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:55 INFO 139687225485120] Epoch[36] Batch [5]#011Speed: 380.62 samples/sec#011loss=-0.075204\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:55 INFO 139687225485120] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157527.0152574, \"EndTime\": 1701157555.9922724, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28976.438283920288, \"count\": 1, \"min\": 28976.438283920288, \"max\": 28976.438283920288}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:55 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.08681058316445 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:55 INFO 139687225485120] #progress_metric: host=algo-1, completed 49.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:55 INFO 139687225485120] #quality_metric: host=algo-1, epoch=36, train loss <loss>=-0.08429685309529304\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:45:55 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:21 INFO 139687225485120] Epoch[37] Batch[0] avg_epoch_loss=-0.114604\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:21 INFO 139687225485120] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=-0.11460362374782562\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:22 INFO 139687225485120] Epoch[37] Batch[5] avg_epoch_loss=-0.110496\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:22 INFO 139687225485120] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=-0.11049557415147622\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:22 INFO 139687225485120] Epoch[37] Batch [5]#011Speed: 382.23 samples/sec#011loss=-0.110496\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:25 INFO 139687225485120] Epoch[37] Batch[10] avg_epoch_loss=-0.086752\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:25 INFO 139687225485120] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=-0.05826017716899514\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:25 INFO 139687225485120] Epoch[37] Batch [10]#011Speed: 130.37 samples/sec#011loss=-0.058260\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:25 INFO 139687225485120] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157555.9923654, \"EndTime\": 1701157585.2065034, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29213.61231803894, \"count\": 1, \"min\": 29213.61231803894, \"max\": 29213.61231803894}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:25 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=23.24249393471177 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:25 INFO 139687225485120] #progress_metric: host=algo-1, completed 50.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:25 INFO 139687225485120] #quality_metric: host=algo-1, epoch=37, train loss <loss>=-0.0867522118867121\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:25 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:51 INFO 139687225485120] Epoch[38] Batch[0] avg_epoch_loss=-0.058389\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:51 INFO 139687225485120] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=-0.05838852375745773\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:52 INFO 139687225485120] Epoch[38] Batch[5] avg_epoch_loss=-0.086803\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:52 INFO 139687225485120] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=-0.08680294392009576\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:52 INFO 139687225485120] Epoch[38] Batch [5]#011Speed: 363.21 samples/sec#011loss=-0.086803\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:54 INFO 139687225485120] Epoch[38] Batch[10] avg_epoch_loss=-0.116438\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:54 INFO 139687225485120] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=-0.1519990846514702\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:54 INFO 139687225485120] Epoch[38] Batch [10]#011Speed: 145.70 samples/sec#011loss=-0.151999\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:54 INFO 139687225485120] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157585.2065816, \"EndTime\": 1701157614.4229777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29215.816259384155, \"count\": 1, \"min\": 29215.816259384155, \"max\": 29215.816259384155}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:54 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.65885955340369 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:54 INFO 139687225485120] #progress_metric: host=algo-1, completed 52.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:54 INFO 139687225485120] #quality_metric: host=algo-1, epoch=38, train loss <loss>=-0.11643755334344777\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:46:54 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:21 INFO 139687225485120] Epoch[39] Batch[0] avg_epoch_loss=-0.086907\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:21 INFO 139687225485120] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=-0.08690738677978516\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:22 INFO 139687225485120] Epoch[39] Batch[5] avg_epoch_loss=-0.068672\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:22 INFO 139687225485120] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=-0.06867192514861624\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:22 INFO 139687225485120] Epoch[39] Batch [5]#011Speed: 355.52 samples/sec#011loss=-0.068672\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:23 INFO 139687225485120] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157614.4230697, \"EndTime\": 1701157643.3996832, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28976.08232498169, \"count\": 1, \"min\": 28976.08232498169, \"max\": 28976.08232498169}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:23 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.15524327969401 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:23 INFO 139687225485120] #progress_metric: host=algo-1, completed 53.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:23 INFO 139687225485120] #quality_metric: host=algo-1, epoch=39, train loss <loss>=-0.07205501506105065\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:23 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:50 INFO 139687225485120] Epoch[40] Batch[0] avg_epoch_loss=-0.033245\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:50 INFO 139687225485120] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=-0.03324452042579651\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:51 INFO 139687225485120] Epoch[40] Batch[5] avg_epoch_loss=-0.101711\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:51 INFO 139687225485120] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=-0.10171090438961983\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:51 INFO 139687225485120] Epoch[40] Batch [5]#011Speed: 375.31 samples/sec#011loss=-0.101711\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:52 INFO 139687225485120] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157643.3998287, \"EndTime\": 1701157672.2993405, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28898.958206176758, \"count\": 1, \"min\": 28898.958206176758, \"max\": 28898.958206176758}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:52 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.00757158962718 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:52 INFO 139687225485120] #progress_metric: host=algo-1, completed 54.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:52 INFO 139687225485120] #quality_metric: host=algo-1, epoch=40, train loss <loss>=-0.09145496748387813\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:47:52 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:19 INFO 139687225485120] Epoch[41] Batch[0] avg_epoch_loss=-0.115118\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:19 INFO 139687225485120] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=-0.11511798202991486\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:20 INFO 139687225485120] Epoch[41] Batch[5] avg_epoch_loss=-0.079199\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:20 INFO 139687225485120] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=-0.07919910984734695\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:20 INFO 139687225485120] Epoch[41] Batch [5]#011Speed: 356.33 samples/sec#011loss=-0.079199\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:21 INFO 139687225485120] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157672.299487, \"EndTime\": 1701157701.5560226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29256.004095077515, \"count\": 1, \"min\": 29256.004095077515, \"max\": 29256.004095077515}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:21 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.397204915793655 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:21 INFO 139687225485120] #progress_metric: host=algo-1, completed 56.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:21 INFO 139687225485120] #quality_metric: host=algo-1, epoch=41, train loss <loss>=-0.07860717549920082\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:21 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:48 INFO 139687225485120] Epoch[42] Batch[0] avg_epoch_loss=-0.117892\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:48 INFO 139687225485120] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=-0.11789245903491974\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:49 INFO 139687225485120] Epoch[42] Batch[5] avg_epoch_loss=-0.088055\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:49 INFO 139687225485120] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=-0.088054650152723\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:49 INFO 139687225485120] Epoch[42] Batch [5]#011Speed: 399.00 samples/sec#011loss=-0.088055\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:50 INFO 139687225485120] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157701.5561368, \"EndTime\": 1701157730.5119534, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28955.2960395813, \"count\": 1, \"min\": 28955.2960395813, \"max\": 28955.2960395813}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:50 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.617893766445327 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:50 INFO 139687225485120] #progress_metric: host=algo-1, completed 57.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:50 INFO 139687225485120] #quality_metric: host=algo-1, epoch=42, train loss <loss>=-0.11416533775627613\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:48:50 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:17 INFO 139687225485120] Epoch[43] Batch[0] avg_epoch_loss=-0.125520\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:17 INFO 139687225485120] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=-0.12552042305469513\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:18 INFO 139687225485120] Epoch[43] Batch[5] avg_epoch_loss=-0.106991\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:18 INFO 139687225485120] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=-0.10699107125401497\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:18 INFO 139687225485120] Epoch[43] Batch [5]#011Speed: 355.78 samples/sec#011loss=-0.106991\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:19 INFO 139687225485120] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157730.5120502, \"EndTime\": 1701157759.7647512, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29252.07018852234, \"count\": 1, \"min\": 29252.07018852234, \"max\": 29252.07018852234}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:19 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.853130284139638 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:19 INFO 139687225485120] #progress_metric: host=algo-1, completed 58.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:19 INFO 139687225485120] #quality_metric: host=algo-1, epoch=43, train loss <loss>=-0.091108288615942\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:19 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:47 INFO 139687225485120] Epoch[44] Batch[0] avg_epoch_loss=-0.131494\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:47 INFO 139687225485120] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=-0.13149425387382507\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:47 INFO 139687225485120] Epoch[44] Batch[5] avg_epoch_loss=-0.112637\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:47 INFO 139687225485120] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=-0.1126369188229243\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:47 INFO 139687225485120] Epoch[44] Batch [5]#011Speed: 378.46 samples/sec#011loss=-0.112637\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:48 INFO 139687225485120] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157759.7648451, \"EndTime\": 1701157788.8400307, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29074.630975723267, \"count\": 1, \"min\": 29074.630975723267, \"max\": 29074.630975723267}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:48 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.77144305904521 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:48 INFO 139687225485120] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:48 INFO 139687225485120] #quality_metric: host=algo-1, epoch=44, train loss <loss>=-0.10228916630148888\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:49:48 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:14 INFO 139687225485120] Epoch[45] Batch[0] avg_epoch_loss=-0.107234\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:14 INFO 139687225485120] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=-0.1072341725230217\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:15 INFO 139687225485120] Epoch[45] Batch[5] avg_epoch_loss=-0.118014\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:15 INFO 139687225485120] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=-0.11801360175013542\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:15 INFO 139687225485120] Epoch[45] Batch [5]#011Speed: 344.99 samples/sec#011loss=-0.118014\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:18 INFO 139687225485120] Epoch[45] Batch[10] avg_epoch_loss=-0.103637\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:18 INFO 139687225485120] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=-0.08638565167784691\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:18 INFO 139687225485120] Epoch[45] Batch [10]#011Speed: 116.69 samples/sec#011loss=-0.086386\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:18 INFO 139687225485120] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157788.8401453, \"EndTime\": 1701157818.5169303, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29676.278352737427, \"count\": 1, \"min\": 29676.278352737427, \"max\": 29676.278352737427}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:18 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.812734082998798 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:18 INFO 139687225485120] #progress_metric: host=algo-1, completed 61.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:18 INFO 139687225485120] #quality_metric: host=algo-1, epoch=45, train loss <loss>=-0.1036372608081861\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:18 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:45 INFO 139687225485120] Epoch[46] Batch[0] avg_epoch_loss=-0.064780\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:45 INFO 139687225485120] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=-0.06478046625852585\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:46 INFO 139687225485120] Epoch[46] Batch[5] avg_epoch_loss=-0.089556\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:46 INFO 139687225485120] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=-0.08955555657545726\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:46 INFO 139687225485120] Epoch[46] Batch [5]#011Speed: 375.09 samples/sec#011loss=-0.089556\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:47 INFO 139687225485120] processed a total of 572 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157818.5170207, \"EndTime\": 1701157847.2196743, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28702.090740203857, \"count\": 1, \"min\": 28702.090740203857, \"max\": 28702.090740203857}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:47 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=19.92878797771231 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:47 INFO 139687225485120] #progress_metric: host=algo-1, completed 62.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:47 INFO 139687225485120] #quality_metric: host=algo-1, epoch=46, train loss <loss>=-0.0912338321407636\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:50:47 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:14 INFO 139687225485120] Epoch[47] Batch[0] avg_epoch_loss=-0.110390\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:14 INFO 139687225485120] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=-0.11039020866155624\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:15 INFO 139687225485120] Epoch[47] Batch[5] avg_epoch_loss=-0.103770\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:15 INFO 139687225485120] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=-0.10376979659001033\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:15 INFO 139687225485120] Epoch[47] Batch [5]#011Speed: 365.81 samples/sec#011loss=-0.103770\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:16 INFO 139687225485120] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157847.2197475, \"EndTime\": 1701157876.393582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29173.26307296753, \"count\": 1, \"min\": 29173.26307296753, \"max\": 29173.26307296753}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:16 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.80662917765744 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:16 INFO 139687225485120] #progress_metric: host=algo-1, completed 64.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:16 INFO 139687225485120] #quality_metric: host=algo-1, epoch=47, train loss <loss>=-0.0998793426901102\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:16 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:43 INFO 139687225485120] Epoch[48] Batch[0] avg_epoch_loss=-0.090128\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:43 INFO 139687225485120] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=-0.09012794494628906\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:44 INFO 139687225485120] Epoch[48] Batch[5] avg_epoch_loss=-0.111702\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:44 INFO 139687225485120] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=-0.11170203983783722\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:44 INFO 139687225485120] Epoch[48] Batch [5]#011Speed: 376.09 samples/sec#011loss=-0.111702\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:45 INFO 139687225485120] Epoch[48] Batch[10] avg_epoch_loss=-0.081642\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:45 INFO 139687225485120] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=-0.04556928351521492\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:45 INFO 139687225485120] Epoch[48] Batch [10]#011Speed: 226.25 samples/sec#011loss=-0.045569\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:45 INFO 139687225485120] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157876.3936737, \"EndTime\": 1701157905.9326842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29538.498163223267, \"count\": 1, \"min\": 29538.498163223267, \"max\": 29538.498163223267}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:45 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.801963034989008 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:45 INFO 139687225485120] #progress_metric: host=algo-1, completed 65.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:45 INFO 139687225485120] #quality_metric: host=algo-1, epoch=48, train loss <loss>=-0.08164169605482709\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:51:45 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:13 INFO 139687225485120] Epoch[49] Batch[0] avg_epoch_loss=-0.041104\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:13 INFO 139687225485120] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=-0.04110376909375191\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:14 INFO 139687225485120] Epoch[49] Batch[5] avg_epoch_loss=-0.072993\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:14 INFO 139687225485120] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=-0.07299253717064857\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:14 INFO 139687225485120] Epoch[49] Batch [5]#011Speed: 378.79 samples/sec#011loss=-0.072993\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:15 INFO 139687225485120] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157905.932774, \"EndTime\": 1701157935.1135051, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29180.243015289307, \"count\": 1, \"min\": 29180.243015289307, \"max\": 29180.243015289307}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:15 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.829738164390573 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:15 INFO 139687225485120] #progress_metric: host=algo-1, completed 66.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:15 INFO 139687225485120] #quality_metric: host=algo-1, epoch=49, train loss <loss>=-0.08147275671362877\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:15 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:42 INFO 139687225485120] Epoch[50] Batch[0] avg_epoch_loss=-0.079902\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:42 INFO 139687225485120] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=-0.07990190386772156\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:43 INFO 139687225485120] Epoch[50] Batch[5] avg_epoch_loss=-0.091317\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:43 INFO 139687225485120] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=-0.09131728981932004\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:43 INFO 139687225485120] Epoch[50] Batch [5]#011Speed: 351.06 samples/sec#011loss=-0.091317\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:44 INFO 139687225485120] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157935.1136003, \"EndTime\": 1701157964.2748075, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29160.626649856567, \"count\": 1, \"min\": 29160.626649856567, \"max\": 29160.626649856567}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:44 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.467214266432332 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:44 INFO 139687225485120] #progress_metric: host=algo-1, completed 68.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:44 INFO 139687225485120] #quality_metric: host=algo-1, epoch=50, train loss <loss>=-0.10283303037285804\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:52:44 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:10 INFO 139687225485120] Epoch[51] Batch[0] avg_epoch_loss=-0.037717\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:10 INFO 139687225485120] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=-0.03771723061800003\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:11 INFO 139687225485120] Epoch[51] Batch[5] avg_epoch_loss=-0.056470\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:11 INFO 139687225485120] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=-0.05647049595912298\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:11 INFO 139687225485120] Epoch[51] Batch [5]#011Speed: 383.27 samples/sec#011loss=-0.056470\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:13 INFO 139687225485120] Epoch[51] Batch[10] avg_epoch_loss=-0.062019\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:13 INFO 139687225485120] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=-0.06867644861340523\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:13 INFO 139687225485120] Epoch[51] Batch [10]#011Speed: 148.36 samples/sec#011loss=-0.068676\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:13 INFO 139687225485120] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157964.2748892, \"EndTime\": 1701157993.5548635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29279.43205833435, \"count\": 1, \"min\": 29279.43205833435, \"max\": 29279.43205833435}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:13 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.814556367247874 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:13 INFO 139687225485120] #progress_metric: host=algo-1, completed 69.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:13 INFO 139687225485120] #quality_metric: host=algo-1, epoch=51, train loss <loss>=-0.062018656256524\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:13 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:40 INFO 139687225485120] Epoch[52] Batch[0] avg_epoch_loss=-0.043026\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:40 INFO 139687225485120] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=-0.04302612319588661\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:41 INFO 139687225485120] Epoch[52] Batch[5] avg_epoch_loss=-0.078950\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:41 INFO 139687225485120] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=-0.07894979851941268\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:41 INFO 139687225485120] Epoch[52] Batch [5]#011Speed: 372.79 samples/sec#011loss=-0.078950\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:42 INFO 139687225485120] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701157993.554944, \"EndTime\": 1701158022.500321, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 28944.83232498169, \"count\": 1, \"min\": 28944.83232498169, \"max\": 28944.83232498169}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:42 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.834538602606564 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:42 INFO 139687225485120] #progress_metric: host=algo-1, completed 70.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:42 INFO 139687225485120] #quality_metric: host=algo-1, epoch=52, train loss <loss>=-0.08128353171050548\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:53:42 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:09 INFO 139687225485120] Epoch[53] Batch[0] avg_epoch_loss=-0.115100\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:09 INFO 139687225485120] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=-0.11510033160448074\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:10 INFO 139687225485120] Epoch[53] Batch[5] avg_epoch_loss=-0.094992\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:10 INFO 139687225485120] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=-0.09499229645977418\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:10 INFO 139687225485120] Epoch[53] Batch [5]#011Speed: 375.53 samples/sec#011loss=-0.094992\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:11 INFO 139687225485120] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158022.5004168, \"EndTime\": 1701158051.6267664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29125.774383544922, \"count\": 1, \"min\": 29125.774383544922, \"max\": 29125.774383544922}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:11 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.60021502924304 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:11 INFO 139687225485120] #progress_metric: host=algo-1, completed 72.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:11 INFO 139687225485120] #quality_metric: host=algo-1, epoch=53, train loss <loss>=-0.07851391863077879\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:11 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:38 INFO 139687225485120] Epoch[54] Batch[0] avg_epoch_loss=-0.124668\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:38 INFO 139687225485120] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=-0.12466788291931152\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:39 INFO 139687225485120] Epoch[54] Batch[5] avg_epoch_loss=-0.104752\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:39 INFO 139687225485120] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=-0.10475186134378116\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:39 INFO 139687225485120] Epoch[54] Batch [5]#011Speed: 396.71 samples/sec#011loss=-0.104752\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:40 INFO 139687225485120] Epoch[54] Batch[10] avg_epoch_loss=-0.116856\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:40 INFO 139687225485120] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=-0.13138043731451035\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:40 INFO 139687225485120] Epoch[54] Batch [10]#011Speed: 251.89 samples/sec#011loss=-0.131380\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:40 INFO 139687225485120] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158051.626862, \"EndTime\": 1701158080.8459704, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29218.54543685913, \"count\": 1, \"min\": 29218.54543685913, \"max\": 29218.54543685913}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:40 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.07490467707748 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:40 INFO 139687225485120] #progress_metric: host=algo-1, completed 73.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:40 INFO 139687225485120] #quality_metric: host=algo-1, epoch=54, train loss <loss>=-0.11685575951229442\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:54:40 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:07 INFO 139687225485120] Epoch[55] Batch[0] avg_epoch_loss=-0.081103\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:07 INFO 139687225485120] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=-0.08110261708498001\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:08 INFO 139687225485120] Epoch[55] Batch[5] avg_epoch_loss=-0.108082\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:08 INFO 139687225485120] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=-0.10808150718609492\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:08 INFO 139687225485120] Epoch[55] Batch [5]#011Speed: 345.61 samples/sec#011loss=-0.108082\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:10 INFO 139687225485120] Epoch[55] Batch[10] avg_epoch_loss=-0.115184\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:10 INFO 139687225485120] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=-0.1237076237797737\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:10 INFO 139687225485120] Epoch[55] Batch [10]#011Speed: 167.70 samples/sec#011loss=-0.123708\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:10 INFO 139687225485120] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158080.8460872, \"EndTime\": 1701158110.570509, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29723.937034606934, \"count\": 1, \"min\": 29723.937034606934, \"max\": 29723.937034606934}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:10 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.8341637553882 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:10 INFO 139687225485120] #progress_metric: host=algo-1, completed 74.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:10 INFO 139687225485120] #quality_metric: host=algo-1, epoch=55, train loss <loss>=-0.11518428745594891\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:10 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:37 INFO 139687225485120] Epoch[56] Batch[0] avg_epoch_loss=-0.168331\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:37 INFO 139687225485120] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=-0.16833147406578064\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:38 INFO 139687225485120] Epoch[56] Batch[5] avg_epoch_loss=-0.116887\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:38 INFO 139687225485120] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=-0.11688720559080441\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:38 INFO 139687225485120] Epoch[56] Batch [5]#011Speed: 378.38 samples/sec#011loss=-0.116887\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:39 INFO 139687225485120] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158110.5705955, \"EndTime\": 1701158139.6893911, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29118.312120437622, \"count\": 1, \"min\": 29118.312120437622, \"max\": 29118.312120437622}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:39 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.22366069501859 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:39 INFO 139687225485120] #progress_metric: host=algo-1, completed 76.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:39 INFO 139687225485120] #quality_metric: host=algo-1, epoch=56, train loss <loss>=-0.10147471502423286\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:55:39 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:07 INFO 139687225485120] Epoch[57] Batch[0] avg_epoch_loss=-0.066421\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:07 INFO 139687225485120] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=-0.06642140448093414\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:07 INFO 139687225485120] Epoch[57] Batch[5] avg_epoch_loss=-0.082405\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:07 INFO 139687225485120] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=-0.08240540822347005\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:07 INFO 139687225485120] Epoch[57] Batch [5]#011Speed: 371.47 samples/sec#011loss=-0.082405\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:08 INFO 139687225485120] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158139.689486, \"EndTime\": 1701158168.8340888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29144.06943321228, \"count\": 1, \"min\": 29144.06943321228, \"max\": 29144.06943321228}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:08 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.964732024653948 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:08 INFO 139687225485120] #progress_metric: host=algo-1, completed 77.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:08 INFO 139687225485120] #quality_metric: host=algo-1, epoch=57, train loss <loss>=-0.09869404658675193\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:08 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:35 INFO 139687225485120] Epoch[58] Batch[0] avg_epoch_loss=-0.024236\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:35 INFO 139687225485120] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=-0.024236466735601425\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:36 INFO 139687225485120] Epoch[58] Batch[5] avg_epoch_loss=-0.009610\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:36 INFO 139687225485120] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=-0.00961037987144664\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:36 INFO 139687225485120] Epoch[58] Batch [5]#011Speed: 372.31 samples/sec#011loss=-0.009610\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:38 INFO 139687225485120] Epoch[58] Batch[10] avg_epoch_loss=-0.053169\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:38 INFO 139687225485120] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=-0.10543899890035391\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:38 INFO 139687225485120] Epoch[58] Batch [10]#011Speed: 123.35 samples/sec#011loss=-0.105439\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:38 INFO 139687225485120] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158168.8341691, \"EndTime\": 1701158198.641897, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29807.14774131775, \"count\": 1, \"min\": 29807.14774131775, \"max\": 29807.14774131775}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:38 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=23.1487146526088 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:38 INFO 139687225485120] #progress_metric: host=algo-1, completed 78.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:38 INFO 139687225485120] #quality_metric: host=algo-1, epoch=58, train loss <loss>=-0.053168843066404486\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:56:38 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:06 INFO 139687225485120] Epoch[59] Batch[0] avg_epoch_loss=-0.065756\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:06 INFO 139687225485120] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=-0.06575588881969452\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:07 INFO 139687225485120] Epoch[59] Batch[5] avg_epoch_loss=-0.070807\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:07 INFO 139687225485120] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=-0.07080679573118687\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:07 INFO 139687225485120] Epoch[59] Batch [5]#011Speed: 339.51 samples/sec#011loss=-0.070807\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:08 INFO 139687225485120] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158198.641984, \"EndTime\": 1701158228.005004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29362.54644393921, \"count\": 1, \"min\": 29362.54644393921, \"max\": 29362.54644393921}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:08 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.353643276142332 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:08 INFO 139687225485120] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:08 INFO 139687225485120] #quality_metric: host=algo-1, epoch=59, train loss <loss>=-0.07945952825248241\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:08 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:35 INFO 139687225485120] Epoch[60] Batch[0] avg_epoch_loss=-0.080263\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:35 INFO 139687225485120] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=-0.08026278764009476\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:35 INFO 139687225485120] Epoch[60] Batch[5] avg_epoch_loss=-0.078905\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:35 INFO 139687225485120] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=-0.07890497582654159\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:35 INFO 139687225485120] Epoch[60] Batch [5]#011Speed: 350.45 samples/sec#011loss=-0.078905\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:37 INFO 139687225485120] Epoch[60] Batch[10] avg_epoch_loss=-0.073523\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:37 INFO 139687225485120] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=-0.06706444174051285\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:37 INFO 139687225485120] Epoch[60] Batch [10]#011Speed: 216.69 samples/sec#011loss=-0.067064\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:37 INFO 139687225485120] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158228.0050902, \"EndTime\": 1701158257.4653852, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29459.815502166748, \"count\": 1, \"min\": 29459.815502166748, \"max\": 29459.815502166748}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:37 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.233586992604103 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:37 INFO 139687225485120] #progress_metric: host=algo-1, completed 81.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:37 INFO 139687225485120] #quality_metric: host=algo-1, epoch=60, train loss <loss>=-0.07352291487834671\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:57:37 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:04 INFO 139687225485120] Epoch[61] Batch[0] avg_epoch_loss=-0.005278\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:04 INFO 139687225485120] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=-0.005278182215988636\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:05 INFO 139687225485120] Epoch[61] Batch[5] avg_epoch_loss=-0.069394\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:05 INFO 139687225485120] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=-0.06939438435559471\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:05 INFO 139687225485120] Epoch[61] Batch [5]#011Speed: 353.87 samples/sec#011loss=-0.069394\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:07 INFO 139687225485120] Epoch[61] Batch[10] avg_epoch_loss=-0.072905\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:07 INFO 139687225485120] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=-0.07711767703294754\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:07 INFO 139687225485120] Epoch[61] Batch [10]#011Speed: 173.50 samples/sec#011loss=-0.077118\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:07 INFO 139687225485120] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158257.4654684, \"EndTime\": 1701158287.2654448, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29799.52120780945, \"count\": 1, \"min\": 29799.52120780945, \"max\": 29799.52120780945}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:07 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.047242019089186 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:07 INFO 139687225485120] #progress_metric: host=algo-1, completed 82.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:07 INFO 139687225485120] #quality_metric: host=algo-1, epoch=61, train loss <loss>=-0.07290497193620964\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:07 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:34 INFO 139687225485120] Epoch[62] Batch[0] avg_epoch_loss=-0.027445\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:34 INFO 139687225485120] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=-0.027444934472441673\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:35 INFO 139687225485120] Epoch[62] Batch[5] avg_epoch_loss=-0.103398\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:35 INFO 139687225485120] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=-0.10339751808593671\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:35 INFO 139687225485120] Epoch[62] Batch [5]#011Speed: 361.39 samples/sec#011loss=-0.103398\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:36 INFO 139687225485120] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158287.2655327, \"EndTime\": 1701158316.7778635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29511.849880218506, \"count\": 1, \"min\": 29511.849880218506, \"max\": 29511.849880218506}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:36 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.008416370095404 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:36 INFO 139687225485120] #progress_metric: host=algo-1, completed 84.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:36 INFO 139687225485120] #quality_metric: host=algo-1, epoch=62, train loss <loss>=-0.09898398797959089\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:58:36 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:04 INFO 139687225485120] Epoch[63] Batch[0] avg_epoch_loss=-0.082390\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:04 INFO 139687225485120] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=-0.08239000290632248\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:05 INFO 139687225485120] Epoch[63] Batch[5] avg_epoch_loss=-0.059730\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:05 INFO 139687225485120] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=-0.059729660395532846\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:05 INFO 139687225485120] Epoch[63] Batch [5]#011Speed: 372.00 samples/sec#011loss=-0.059730\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:06 INFO 139687225485120] processed a total of 593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158316.7779572, \"EndTime\": 1701158346.5560005, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29777.402639389038, \"count\": 1, \"min\": 29777.402639389038, \"max\": 29777.402639389038}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:06 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=19.914324908909514 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:06 INFO 139687225485120] #progress_metric: host=algo-1, completed 85.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:06 INFO 139687225485120] #quality_metric: host=algo-1, epoch=63, train loss <loss>=-0.06602265946567058\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:06 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:34 INFO 139687225485120] Epoch[64] Batch[0] avg_epoch_loss=-0.082438\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:34 INFO 139687225485120] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=-0.08243797719478607\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:35 INFO 139687225485120] Epoch[64] Batch[5] avg_epoch_loss=-0.091216\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:35 INFO 139687225485120] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=-0.09121593832969666\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:35 INFO 139687225485120] Epoch[64] Batch [5]#011Speed: 397.94 samples/sec#011loss=-0.091216\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:35 INFO 139687225485120] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158346.5561182, \"EndTime\": 1701158375.8959723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29339.290142059326, \"count\": 1, \"min\": 29339.290142059326, \"max\": 29339.290142059326}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:35 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.688873013698416 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:35 INFO 139687225485120] #progress_metric: host=algo-1, completed 86.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:35 INFO 139687225485120] #quality_metric: host=algo-1, epoch=64, train loss <loss>=-0.0788748323917389\u001b[0m\n",
      "\u001b[34m[11/28/2023 07:59:35 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:03 INFO 139687225485120] Epoch[65] Batch[0] avg_epoch_loss=-0.132177\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:03 INFO 139687225485120] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=-0.13217677175998688\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:04 INFO 139687225485120] Epoch[65] Batch[5] avg_epoch_loss=-0.095128\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:04 INFO 139687225485120] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=-0.09512848779559135\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:04 INFO 139687225485120] Epoch[65] Batch [5]#011Speed: 359.05 samples/sec#011loss=-0.095128\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:05 INFO 139687225485120] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158375.8960655, \"EndTime\": 1701158405.008534, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29111.92512512207, \"count\": 1, \"min\": 29111.92512512207, \"max\": 29111.92512512207}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:05 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=21.36572781138321 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:05 INFO 139687225485120] #progress_metric: host=algo-1, completed 88.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:05 INFO 139687225485120] #quality_metric: host=algo-1, epoch=65, train loss <loss>=-0.08784841988235711\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:05 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:32 INFO 139687225485120] Epoch[66] Batch[0] avg_epoch_loss=-0.136788\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:32 INFO 139687225485120] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=-0.13678789138793945\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:33 INFO 139687225485120] Epoch[66] Batch[5] avg_epoch_loss=-0.116991\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:33 INFO 139687225485120] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=-0.11699143300453822\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:33 INFO 139687225485120] Epoch[66] Batch [5]#011Speed: 368.25 samples/sec#011loss=-0.116991\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:34 INFO 139687225485120] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158405.0086205, \"EndTime\": 1701158434.1101127, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29100.961446762085, \"count\": 1, \"min\": 29100.961446762085, \"max\": 29100.961446762085}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:34 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.411609952115047 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:34 INFO 139687225485120] #progress_metric: host=algo-1, completed 89.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:34 INFO 139687225485120] #quality_metric: host=algo-1, epoch=66, train loss <loss>=-0.12483260110020637\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:00:34 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:01 INFO 139687225485120] Epoch[67] Batch[0] avg_epoch_loss=-0.115682\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:01 INFO 139687225485120] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=-0.11568181216716766\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:02 INFO 139687225485120] Epoch[67] Batch[5] avg_epoch_loss=-0.102642\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:02 INFO 139687225485120] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=-0.10264183208346367\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:02 INFO 139687225485120] Epoch[67] Batch [5]#011Speed: 319.53 samples/sec#011loss=-0.102642\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:03 INFO 139687225485120] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158434.1101966, \"EndTime\": 1701158463.572964, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29462.18991279602, \"count\": 1, \"min\": 29462.18991279602, \"max\": 29462.18991279602}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:03 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=20.568551361762054 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:03 INFO 139687225485120] #progress_metric: host=algo-1, completed 90.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:03 INFO 139687225485120] #quality_metric: host=algo-1, epoch=67, train loss <loss>=-0.10235733333975076\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:03 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:30 INFO 139687225485120] Epoch[68] Batch[0] avg_epoch_loss=-0.089545\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:30 INFO 139687225485120] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=-0.08954460918903351\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:31 INFO 139687225485120] Epoch[68] Batch[5] avg_epoch_loss=-0.089156\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:31 INFO 139687225485120] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=-0.08915575593709946\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:31 INFO 139687225485120] Epoch[68] Batch [5]#011Speed: 397.86 samples/sec#011loss=-0.089156\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] Epoch[68] Batch[10] avg_epoch_loss=-0.088784\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=-0.08833870813250541\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] Epoch[68] Batch [10]#011Speed: 177.16 samples/sec#011loss=-0.088339\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158463.5731843, \"EndTime\": 1701158493.1937304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29619.788646697998, \"count\": 1, \"min\": 29619.788646697998, \"max\": 29619.788646697998}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] #throughput_metric: host=algo-1, train throughput=22.552392585026222 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] #progress_metric: host=algo-1, completed 92.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] #quality_metric: host=algo-1, epoch=68, train loss <loss>=-0.0887843705713749\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] Loading parameters from best epoch (28)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158493.1938193, \"EndTime\": 1701158493.2122355, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 17.84825325012207, \"count\": 1, \"min\": 17.84825325012207, \"max\": 17.84825325012207}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] stopping training now\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] Final loss: -0.12969364462928337 (occurred at epoch 28)\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] #quality_metric: host=algo-1, train final_loss <loss>=-0.12969364462928337\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 WARNING 139687225485120] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:33 INFO 139687225485120] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158493.212308, \"EndTime\": 1701158495.3021026, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 2089.080572128296, \"count\": 1, \"min\": 2089.080572128296, \"max\": 2089.080572128296}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:35 INFO 139687225485120] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158495.30219, \"EndTime\": 1701158495.518996, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2306.020736694336, \"count\": 1, \"min\": 2306.020736694336, \"max\": 2306.020736694336}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:35 INFO 139687225485120] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:35 INFO 139687225485120] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158495.519076, \"EndTime\": 1701158495.5333796, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 14.26839828491211, \"count\": 1, \"min\": 14.26839828491211, \"max\": 14.26839828491211}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:35 INFO 139687225485120] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:35 INFO 139687225485120] #memory_usage::<batchbuffer> = 577.45849609375 mb\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:35 INFO 139687225485120] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158495.533437, \"EndTime\": 1701158495.5400646, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.026941299438476562, \"count\": 1, \"min\": 0.026941299438476562, \"max\": 0.026941299438476562}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158495.5401454, \"EndTime\": 1701158505.8411915, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 10301.151514053345, \"count\": 1, \"min\": 10301.151514053345, \"max\": 10301.151514053345}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, RMSE): 0.5009041358578602\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, mean_absolute_QuantileLoss): 25.058020744680107\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, mean_wQuantileLoss): 1.0023208297872044\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.1]): 0.20234134796028957\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.2]): 0.40312422399409115\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.3]): 0.6036003065307158\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.4]): 0.80389426183654\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.5]): 1.0039153965075094\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.6]): 1.2037895898359128\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.7]): 1.4029295990585815\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.8]): 1.6010779488347469\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #test_score (algo-1, wQuantileLoss[0.9]): 1.7962147935264512\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #quality_metric: host=algo-1, test RMSE <loss>=0.5009041358578602\u001b[0m\n",
      "\u001b[34m[11/28/2023 08:01:45 INFO 139687225485120] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=1.0023208297872044\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701158505.8412693, \"EndTime\": 1701158505.9634552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 5.566120147705078, \"count\": 1, \"min\": 5.566120147705078, \"max\": 5.566120147705078}, \"totaltime\": {\"sum\": 2040601.506471634, \"count\": 1, \"min\": 2040601.506471634, \"max\": 2040601.506471634}}}\u001b[0m\n",
      "\n",
      "2023-11-28 08:02:01 Uploading - Uploading generated training model\n",
      "2023-11-28 08:02:01 Completed - Training job completed\n",
      "Training seconds: 2195\n",
      "Billable seconds: 2195\n",
      "CPU times: user 5.57 s, sys: 179 ms, total: 5.75 s\n",
      "Wall time: 38min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aafd68e5-81e1-4f2f-9329-956c2eb27442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7622bada-5720-46d5-999a-2a46ee361b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.Predictor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            # serializer=JSONSerializer(),\n",
    "            serializer=IdentitySerializer(content_type=\"application/json\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        ts,\n",
    "        cat=None,\n",
    "        dynamic_feat=None,\n",
    "        num_samples=100,\n",
    "        return_samples=False,\n",
    "        quantiles=[\"0.1\", \"0.5\", \"0.9\"],\n",
    "    ):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + ts.index.freq\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "\n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(\n",
    "            ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None\n",
    "        )\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles,\n",
    "        }\n",
    "\n",
    "        http_request_data = {\"instances\": [instance], \"configuration\": configuration}\n",
    "\n",
    "        return json.dumps(http_request_data).encode(\"utf-8\")\n",
    "\n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode(\"utf-8\"))[\"predictions\"][0]\n",
    "        prediction_length = len(next(iter(predictions[\"quantiles\"].values())))\n",
    "        prediction_index = pd.date_range(\n",
    "            start=prediction_time, freq=freq, periods=prediction_length\n",
    "        )\n",
    "        if return_samples:\n",
    "            dict_of_samples = {\"sample_\" + str(i): s for i, s in enumerate(predictions[\"samples\"])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(\n",
    "            data={**predictions[\"quantiles\"], **dict_of_samples}, index=prediction_index\n",
    "        )\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "\n",
    "\n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]\n",
    "\n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8725cf50-22ea-47a8-ad48-013f4bfef1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: deepar-capstone-job-2023-11-28-08-04-40-688\n",
      "INFO:sagemaker:Creating endpoint-config with name deepar-capstone-job-2023-11-28-08-04-40-688\n",
      "INFO:sagemaker:Creating endpoint with name deepar-capstone-job-2023-11-28-08-04-40-688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac862a1-738a-47d3-bf92-07a664f2092e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeseries[0].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f76bbe-40ca-4c00-92ad-a75ee123c932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coefficients = np.polyfit(np.asarray(timeseries[0]).astype(float), y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d8f8ae84-0c10-4a77-913c-4cf0675ea1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Timestamp' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeseries\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[92], line 30\u001b[0m, in \u001b[0;36mDeepARPredictor.predict\u001b[0;34m(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     12\u001b[0m     ts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     quantiles\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.9\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     18\u001b[0m ):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    corresponding category listed in `cat`.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Return value: list of `pandas.DataFrame` objects, each containing the predictions\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     prediction_time \u001b[38;5;241m=\u001b[39m \u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreq\u001b[49m\n\u001b[1;32m     31\u001b[0m     quantiles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(q) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m quantiles]\n\u001b[1;32m     32\u001b[0m     req \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Timestamp' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "predictor.predict(ts=timeseries[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc6ab1-2a60-4754-9b18-e5159dd6f80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(\n",
    "    predictor,\n",
    "    target_ts,\n",
    "    cat=None,\n",
    "    dynamic_feat=None,\n",
    "    forecast_date=end_training,\n",
    "    show_samples=False,\n",
    "    plot_history=7 * 12,\n",
    "    confidence=80,\n",
    "):\n",
    "    freq = target_ts.index.freq\n",
    "    print(\n",
    "        \"calling served model to generate predictions starting from {}\".format(str(forecast_date))\n",
    "    )\n",
    "    assert confidence > 50 and confidence < 100\n",
    "    low_quantile = 0.5 - confidence * 0.005\n",
    "    up_quantile = confidence * 0.005 + 0.5\n",
    "\n",
    "    # we first construct the argument to call our model\n",
    "    args = {\n",
    "        \"ts\": target_ts[:forecast_date],\n",
    "        \"return_samples\": show_samples,\n",
    "        \"quantiles\": [low_quantile, 0.5, up_quantile],\n",
    "        \"num_samples\": 100,\n",
    "    }\n",
    "\n",
    "    if dynamic_feat is not None:\n",
    "        args[\"dynamic_feat\"] = dynamic_feat\n",
    "        fig = plt.figure(figsize=(20, 6))\n",
    "        ax = plt.subplot(2, 1, 1)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(20, 3))\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "    if cat is not None:\n",
    "        args[\"cat\"] = cat\n",
    "        ax.text(0.9, 0.9, \"cat = {}\".format(cat), transform=ax.transAxes)\n",
    "\n",
    "    # call the end point to get the prediction\n",
    "    prediction = predictor.predict(**args)\n",
    "\n",
    "    # plot the samples\n",
    "    if show_samples:\n",
    "        for key in prediction.keys():\n",
    "            if \"sample\" in key:\n",
    "                prediction[key].plot(color=\"lightskyblue\", alpha=0.2, label=\"_nolegend_\")\n",
    "\n",
    "    # plot the target\n",
    "    target_section = target_ts[\n",
    "        forecast_date - plot_history * freq : forecast_date + prediction_length * freq\n",
    "    ]\n",
    "    target_section.plot(color=\"black\", label=\"target\")\n",
    "\n",
    "    # plot the confidence interval and the median predicted\n",
    "    ax.fill_between(\n",
    "        prediction[str(low_quantile)].index,\n",
    "        prediction[str(low_quantile)].values,\n",
    "        prediction[str(up_quantile)].values,\n",
    "        color=\"b\",\n",
    "        alpha=0.3,\n",
    "        label=\"{}% confidence interval\".format(confidence),\n",
    "    )\n",
    "    prediction[\"0.5\"].plot(color=\"b\", label=\"P50\")\n",
    "    ax.legend(loc=2)\n",
    "\n",
    "    # fix the scale as the samples may change it\n",
    "    ax.set_ylim(target_section.min() * 0.5, target_section.max() * 1.5)\n",
    "\n",
    "    if dynamic_feat is not None:\n",
    "        for i, f in enumerate(dynamic_feat, start=1):\n",
    "            ax = plt.subplot(len(dynamic_feat) * 2, 1, len(dynamic_feat) + i, sharex=ax)\n",
    "            feat_ts = pd.Series(\n",
    "                index=pd.date_range(\n",
    "                    start=target_ts.index[0], freq=target_ts.index.freq, periods=len(f)\n",
    "                ),\n",
    "                data=f,\n",
    "            )\n",
    "            feat_ts[\n",
    "                forecast_date - plot_history * freq : forecast_date + prediction_length * freq\n",
    "            ].plot(ax=ax, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a8fa0-83b0-4877-b1d6-ec13e0f89740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
